# =============================================================================
# IMPORTANT NOTICE & CROSS-PLATFORM COMPATIBILITY - 2025/6/27
# =============================================================================
# This script was developed and tested exclusively in Japanese environments.
# Users in different locales may encounter encoding/character set issues.
# Please ensure UTF-8 support and proper Japanese font rendering.
# 
# REQUIREMENTS:
# - UTF-8 encoding support
# - Japanese locale support (optional but recommended)
# - Python packages: feedparser, requests, google-generativeai
# - Valid API keys for Gemini and email services
# =============================================================================

## Background

This script is an AI-enhanced version of the personalized news generator,
originally created to support the digital dignity of an elderly woman born in 1947.

Using Gemini 2.0 Flash (via the API), this version adds:
â€“ Automatic selection and sorting of top international news articles
â€“ Optional translation using a large language model (currently limited by quota)

This script is part of the same project as:
**[AI and Elderly Dignity: A Speech Draft for Researchers](https://www.academia.edu/129405187/AI_and_Elderly_Dignity)**  
by Trgr KarasuToragara (2025)

# NOTE:
# - API key (GEMINI_API_KEY) must be provided separately and should NOT be published.
# - For simplicity, configuration is embedded in this script.
# - Some comments remain in Japanese for clarity and maintainability.


#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è - Gemini 2.0 AIç‰ˆï¼ˆå…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆï¼‰

é©æ–°çš„æ”¹å–„ï¼š
1. å…¨ä»¶ãƒãƒƒãƒç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆå…¨20ä»¶ã‚’1å›ã®APIå‘¼ã³å‡ºã—ã§å‡¦ç†ï¼‰
2. ç¿»è¨³å¾Œé‡è¦åº¦ã‚½ãƒ¼ãƒˆï¼ˆå’Œè¨³ã‚’è¦‹ã¦åˆ¤æ–­â†’ä¸¦ã³æ›¿ãˆï¼‰
3. å…¨è¨˜äº‹ã§åŸæ–‡ãƒ»å’Œè¨³ä½µè¨˜
4. ç©¶æ¥µã®APIåŠ¹ç‡åŒ–: 20å› â†’ 1å›ï¼ˆ20å€åŠ¹ç‡åŒ–ï¼‰
5. NHKå……å®Ÿãƒ»Yahooå‰Šé™¤ãƒ»å›½å†…45ä»¶ãƒ»å„ªå…ˆåº¦åˆ¥èƒŒæ™¯è‰²
"""

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from datetime import datetime, date
import random
import time
import re
import json
import ssl
import urllib3

# å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
    import feedparser
    import requests
    from google import genai
    LIBS_AVAILABLE = True
except ImportError:
    LIBS_AVAILABLE = False
    print("âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³: pip install feedparser requests google-generativeai")

# SSLè­¦å‘Šã‚’ç„¡åŠ¹åŒ–ï¼ˆè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ssl._create_default_https_context = ssl._create_unverified_context

# ======================================
# è¨­å®šã‚¨ãƒªã‚¢
# ======================================

SENDER_EMAIL = "your_email@gmail.com"
SENDER_PASSWORD = "your_app_password"
RECIPIENTS = ["recipient1@example.com", "recipient2@example.com"]
SENDER_NAME = ""
LOCATION_NAME = ""
LATITUDE = 
LONGITUDE = 

# Gemini APIè¨­å®š
GEMINI_API_KEY = "your_gemini_api_key"
gemini_client = genai.Client(api_key=GEMINI_API_KEY)

# Gemini ãƒ¢ãƒ‡ãƒ«é¸æŠ
GEMINI_MODEL = "gemini-2.0-flash"

# ç¿»è¨³åˆ¶é™è¨­å®šï¼ˆå…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆï¼‰
ENABLE_BATCH_TRANSLATION = True  # ãƒãƒƒãƒç¿»è¨³æœ‰åŠ¹/ç„¡åŠ¹
MAX_BATCH_SIZE = 20  # ä¸€åº¦ã«ç¿»è¨³ã™ã‚‹æœ€å¤§ä»¶æ•°
TRANSLATION_DELAY = 3

# ======================================
# ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ï¼ˆNHKå……å®Ÿãƒ»Yahooå‰Šé™¤ç‰ˆï¼‰
# ======================================

# NHKå……å®Ÿç‰ˆï¼ˆåœ°æ–¹ãƒ»æ–‡åŒ–ç³»è¿½åŠ ï¼‰
JAPANESE_NEWS_SOURCES = [
    ("NHK ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹", "https://www.nhk.or.jp/rss/news/cat0.xml", 20),  # å¢—é‡
    ("NHK ç¤¾ä¼š", "https://www.nhk.or.jp/rss/news/cat1.xml", 15),  # å¢—é‡
    ("NHK æ”¿æ²»", "https://www.nhk.or.jp/rss/news/cat4.xml", 15),  # å¢—é‡
    ("NHK çµŒæ¸ˆ", "https://www.nhk.or.jp/rss/news/cat5.xml", 15),  # å¢—é‡
    ("NHK å›½éš›", "https://www.nhk.or.jp/rss/news/cat6.xml", 12),
    ("NHK ç§‘å­¦æ–‡åŒ–", "https://www.nhk.or.jp/rss/news/cat3.xml", 12),
    ("NHK ã‚¹ãƒãƒ¼ãƒ„", "https://www.nhk.or.jp/rss/news/cat7.xml", 8),  # è¿½åŠ 
    ("NHK æ°—è±¡ç½å®³", "https://www.nhk.or.jp/rss/news/cat2.xml", 10),  # è¿½åŠ 
    # Yahooãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯å…¨ã¦ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆ
    # ("Yahooä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹", "https://news.yahoo.co.jp/rss/topics/top-picks.xml", 12),
    # ("Yahooå›½å†…", "https://news.yahoo.co.jp/rss/topics/domestic.xml", 10),
    # ("YahooçµŒæ¸ˆ", "https://news.yahoo.co.jp/rss/topics/business.xml", 8),
    # ("Yahooå›½éš›", "https://news.yahoo.co.jp/rss/topics/world.xml", 8),
    ("æ™‚äº‹é€šä¿¡", "https://www.jiji.com/rss/ranking.rdf", 10),
    ("æœæ—¥æ–°è", "https://www.asahi.com/rss/asahi/newsheadlines.rdf", 10),
]

INTERNATIONAL_NEWS_SOURCES = [
    ("BBC World", "http://feeds.bbci.co.uk/news/world/rss.xml", 8),
    ("BBC UK", "http://feeds.bbci.co.uk/news/uk/rss.xml", 5),
    ("The Guardian World", "https://www.theguardian.com/world/rss", 5),
    ("ABC Australia", "https://www.abc.net.au/news/feed/45924/rss.xml", 4),
    ("Deutsche Welle", "https://rss.dw.com/rdf/rss-en-all", 5),
    ("France 24", "https://www.france24.com/en/rss", 4),
    ("Al Jazeera", "https://www.aljazeera.com/xml/rss/all.xml", 6),
    ("El PaÃ­s EspaÃ±a", "https://feeds.elpais.com/mrss-s/pages/ep/site/elpais.com/portada", 6),
]

EXCLUDE_KEYWORDS = [
    "å¥³æ€§è‡ªèº«", "å¥³æ€§ã‚»ãƒ–ãƒ³", "é€±åˆŠå¥³æ€§", "FLASH", "FRIDAY", "é€±åˆŠæ–‡æ˜¥", "é€±åˆŠæ–°æ½®",
    "æ—¥åˆŠã‚²ãƒ³ãƒ€ã‚¤", "æ±ã‚¹ãƒ", "ã‚µãƒ³ã‚¹ãƒ", "ãƒ‡ã‚¤ãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒ„", "å¤•åˆŠãƒ•ã‚¸", "æ—¥åˆŠã‚¹ãƒãƒ¼ãƒ„",
    "èŠ¸èƒ½", "ä¸å€«", "æµ®æ°—", "é›¢å©š", "ç‚ä¸Š", "æš´éœ²", "æ¿€æ€’", "è¡æ’ƒ", 
    "ç·Šæ€¥äº‹æ…‹", "å¤§ç‚ä¸Š", "æ‰¹åˆ¤æ®ºåˆ°", "ç‰©è­°", "è©±é¡Œé¨’ç„¶", "è³›å¦ä¸¡è«–",
]

# ======================================
# ã‚¿ã‚°åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
# ======================================

ARTICLE_CATEGORIES = {
    "æ”¿æ²»ãƒ»å¤–äº¤": {
        "icon": "ğŸ›ï¸",
        "keywords": ["election", "government", "president", "minister", "parliament", "congress", "summit", "diplomacy", "vote", "policy", "leader", "official", "political", "democracy", "campaign", "referendum", "æ”¿æ²»", "å¤–äº¤", "é¦–ç›¸", "å¤§çµ±é ˜", "å›½ä¼š", "é¸æŒ™", "æ”¿åºœ"]
    },
    "ç´›äº‰ãƒ»è»äº‹": {
        "icon": "âš”ï¸", 
        "keywords": ["war", "conflict", "military", "attack", "bombing", "missile", "drone", "army", "navy", "defense", "weapons", "soldiers", "battle", "invasion", "ceasefire", "terrorism", "security", "forces", "æˆ¦äº‰", "è»äº‹", "æ”»æ’ƒ", "ãƒŸã‚µã‚¤ãƒ«", "è‡ªè¡›éšŠ", "é˜²è¡›", "åœæˆ¦", "ãƒ†ãƒ­"]
    },
    "çµŒæ¸ˆãƒ»å¸‚å ´": {
        "icon": "ğŸ’¹",
        "keywords": ["economy", "market", "trade", "business", "company", "financial", "bank", "investment", "GDP", "inflation", "recession", "stock", "currency", "oil", "gas", "energy", "industry", "growth", "çµŒæ¸ˆ", "å¸‚å ´", "æ ªä¾¡", "æŠ•è³‡", "é‡‘è", "ä¼æ¥­", "æ¥­ç¸¾", "æ™¯æ°—"]
    },
    "ç’°å¢ƒãƒ»æ°—å€™": {
        "icon": "ğŸŒ",
        "keywords": ["climate", "environment", "global warming", "renewable", "carbon", "pollution", "green", "sustainability", "biodiversity", "conservation", "eco", "solar", "wind", "emissions", "nature", "ç’°å¢ƒ", "æ°—å€™", "æ¸©æš–åŒ–", "è„±ç‚­ç´ ", "å†ç”Ÿå¯èƒ½", "ã‚¨ã‚³"]
    },
    "ç¤¾ä¼šãƒ»æ–‡åŒ–": {
        "icon": "ğŸ‘¥",
        "keywords": ["society", "social", "community", "education", "school", "university", "culture", "religion", "family", "youth", "elderly", "women", "gender", "rights", "protest", "demonstration", "ç¤¾ä¼š", "æ•™è‚²", "å­¦æ ¡", "æ–‡åŒ–", "å®—æ•™", "æ¨©åˆ©", "æŠ—è­°"]
    },
    "ç§‘å­¦ãƒ»æŠ€è¡“": {
        "icon": "ğŸ”¬",
        "keywords": ["science", "technology", "research", "AI", "computer", "internet", "cyber", "space", "satellite", "innovation", "discovery", "study", "experiment", "data", "digital", "ç§‘å­¦", "æŠ€è¡“", "ç ”ç©¶", "AI", "å®‡å®™", "IT", "ãƒ‡ã‚¸ã‚¿ãƒ«", "å®Ÿé¨“"]
    },
    "å¥åº·ãƒ»åŒ»ç™‚": {
        "icon": "ğŸ¥",
        "keywords": ["health", "medical", "hospital", "doctor", "patient", "disease", "virus", "pandemic", "treatment", "vaccine", "medicine", "healthcare", "mental health", "outbreak", "surgery", "å¥åº·", "åŒ»ç™‚", "ç—…é™¢", "åŒ»å¸«", "æ‚£è€…", "ã‚¦ã‚¤ãƒ«ã‚¹", "æ²»ç™‚", "ãƒ¯ã‚¯ãƒãƒ³"]
    },
    "ç½å®³ãƒ»äº‹æ•…": {
        "icon": "ğŸš¨",
        "keywords": ["earthquake", "tsunami", "flood", "fire", "hurricane", "tornado", "disaster", "emergency", "accident", "crash", "explosion", "rescue", "evacuation", "damage", "victims", "alert", "åœ°éœ‡", "æ´¥æ³¢", "ç«ç½", "ç½å®³", "äº‹æ•…", "ç·Šæ€¥", "é¿é›£", "è¢«å®³"]
    }
}

def analyze_article_tags(title, summary):
    """è¨˜äº‹ã‚¿ã‚°åˆ†æ"""
    text = (title + " " + summary).lower()
    scores = {}
    
    for category, data in ARTICLE_CATEGORIES.items():
        score = sum(1 for keyword in data["keywords"] if keyword in text)
        if score > 0:
            scores[category] = score
    
    # ä¸Šä½3ã¤ã¾ã§ã®ã‚¿ã‚°
    sorted_tags = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]
    
    return [
        {
            "name": category,
            "icon": ARTICLE_CATEGORIES[category]["icon"]
        }
        for category, score in sorted_tags
    ] if sorted_tags else [{"name": "ä¸€èˆ¬", "icon": "ğŸ“°"}]

# ======================================
# ãƒãƒƒãƒç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ ï¼ˆAPIç¯€ç´„ç‰ˆï¼‰
# ======================================

def batch_translate_articles(articles_list):
    """ãƒãƒƒãƒç¿»è¨³ï¼ˆè¤‡æ•°è¨˜äº‹ã‚’1å›ã®APIå‘¼ã³å‡ºã—ã§ç¿»è¨³ï¼‰"""
    if not articles_list:
        return {}
    
    try:
        # ãƒãƒƒãƒç¿»è¨³ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
        titles_text = ""
        for i, article in enumerate(articles_list, 1):
            titles_text += f"{i}. {article['original_title']}\n"
        
        prompt = f"""ä»¥ä¸‹ã®{len(articles_list)}ä»¶ã®è‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‚’ã€ãã‚Œãã‚Œè‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

è‹±èªã‚¿ã‚¤ãƒˆãƒ«ä¸€è¦§ï¼š
{titles_text}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
{{
    "translations": [
        {{"id": 1, "translation": "1ã¤ç›®ã®æ—¥æœ¬èªç¿»è¨³"}},
        {{"id": 2, "translation": "2ã¤ç›®ã®æ—¥æœ¬èªç¿»è¨³"}},
        ...
    ]
}}

æ³¨æ„ï¼šç¿»è¨³ã®ã¿ã‚’å‡ºåŠ›ã—ã€èª¬æ˜ã¯ä¸è¦ã§ã™ã€‚"""
        
        print(f"ğŸš€ ãƒãƒƒãƒç¿»è¨³å®Ÿè¡Œä¸­: {len(articles_list)}ä»¶ã‚’1å›ã®APIå‘¼ã³å‡ºã—ã§å‡¦ç†...")
        
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt
        )
        result_text = response.text.strip()
        
        # JSONãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡º
        if "```json" in result_text:
            json_start = result_text.find("```json") + 7
            json_end = result_text.find("```", json_start)
            result_text = result_text[json_start:json_end].strip()
        elif "{" in result_text and "}" in result_text:
            json_start = result_text.find("{")
            json_end = result_text.rfind("}") + 1
            result_text = result_text[json_start:json_end]
        
        result = json.loads(result_text)
        translations = result.get("translations", [])
        
        # ç¿»è¨³çµæœã‚’ãƒãƒƒãƒ”ãƒ³ã‚°
        translation_map = {}
        for trans in translations:
            article_id = trans.get("id", 0) - 1  # 0ãƒ™ãƒ¼ã‚¹ã«å¤‰æ›
            translation = trans.get("translation", "")
            if 0 <= article_id < len(articles_list) and translation:
                original_title = articles_list[article_id]['original_title']
                translation_map[original_title] = translation
        
        print(f"âœ… ãƒãƒƒãƒç¿»è¨³æˆåŠŸ: {len(translation_map)}/{len(articles_list)}ä»¶ã®ç¿»è¨³ã‚’å–å¾—")
        return translation_map
        
    except Exception as e:
        print(f"âŒ ãƒãƒƒãƒç¿»è¨³å¤±æ•—: {str(e)}")
        return {}

def translate_top_articles_only(title, summary=""):
    """å€‹åˆ¥ç¿»è¨³ï¼ˆãƒãƒƒãƒç¿»è¨³ã®ä»£æ›¿ãƒ»ç·Šæ€¥ç”¨ï¼‰"""
    try:
        prompt = f"""ä»¥ä¸‹ã®è‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªç„¶ãªæ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚

è‹±èª: {title}

JSONã§å‡ºåŠ›ï¼š
{{
    "translation": "æ—¥æœ¬èªç¿»è¨³"
}}"""
        
        response = gemini_client.models.generate_content(
            model=GEMINI_MODEL,
            contents=prompt
        )
        result_text = response.text.strip()
        
        # JSONãƒ–ãƒ­ãƒƒã‚¯æŠ½å‡º
        if "```json" in result_text:
            json_start = result_text.find("```json") + 7
            json_end = result_text.find("```", json_start)
            result_text = result_text[json_start:json_end].strip()
        elif "{" in result_text and "}" in result_text:
            json_start = result_text.find("{")
            json_end = result_text.rfind("}") + 1
            result_text = result_text[json_start:json_end]
        
        result = json.loads(result_text)
        translation = result.get("translation", "")
        
        if translation and translation != title:
            print(f"âœ… å€‹åˆ¥ç¿»è¨³æˆåŠŸ: {title[:30]}... â†’ {translation[:30]}...")
            return translation
        else:
            print(f"âš ï¸  å€‹åˆ¥ç¿»è¨³çµæœãŒä¸é©åˆ‡ã€å…ƒã‚¿ã‚¤ãƒˆãƒ«ä½¿ç”¨")
            return title
        
    except Exception as e:
        print(f"âŒ å€‹åˆ¥ç¿»è¨³å¤±æ•—: {str(e)} - å…ƒã‚¿ã‚¤ãƒˆãƒ«ä½¿ç”¨")
        return title

def process_articles_simplified(articles):
    """å…¨ä»¶ãƒãƒƒãƒç¿»è¨³ï¼‹é‡è¦åº¦ã‚½ãƒ¼ãƒˆå‡¦ç†"""
    analyzed_articles = []
    api_calls_used = 0
    translation_count = 0
    
    print(f"ğŸ“° è¨˜äº‹å‡¦ç†é–‹å§‹ï¼ˆå…¨ä»¶ãƒãƒƒãƒç¿»è¨³: {ENABLE_BATCH_TRANSLATION}ï¼‰...")
    
    # å›½å†…ãƒ»å›½éš›è¨˜äº‹ã‚’åˆ†é›¢
    international_articles = [a for a in articles if a['is_international']]
    domestic_articles = [a for a in articles if not a['is_international']]
    
    # å›½éš›è¨˜äº‹ã®å…¨ä»¶ãƒãƒƒãƒç¿»è¨³
    translation_map = {}
    if ENABLE_BATCH_TRANSLATION and international_articles:
        try:
            # å…¨ã¦ã®å›½éš›è¨˜äº‹ã‚’ä¸€åº¦ã«ç¿»è¨³ï¼ˆ1å›ã®APIå‘¼ã³å‡ºã—ï¼‰
            batch_size = min(len(international_articles), MAX_BATCH_SIZE)
            articles_to_translate = international_articles[:batch_size]
            
            print(f"ğŸš€ å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å®Ÿè¡Œ: {len(articles_to_translate)}ä»¶ã‚’1å›ã®APIå‘¼ã³å‡ºã—ã§å‡¦ç†...")
            translation_map = batch_translate_articles(articles_to_translate)
            api_calls_used = 1 if translation_map else 0
            translation_count = len(translation_map)
            
            print(f"ğŸ¯ å…¨ä»¶ãƒãƒƒãƒç¿»è¨³çµæœ: {translation_count}/{len(articles_to_translate)}ä»¶æˆåŠŸ")
            
        except Exception as e:
            print(f"âš ï¸  å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å¤±æ•—: {str(e)}")
            translation_map = {}
    
    # å›½éš›è¨˜äº‹ã®ç¿»è¨³çµæœé©ç”¨
    for article in international_articles:
        try:
            title = article['original_title']
            
            if title in translation_map:
                # ãƒãƒƒãƒç¿»è¨³æˆåŠŸ
                translated_title = translation_map[title]
                article.update({
                    'title': translated_title,
                    'has_translation': True,
                    'importance': 3,  # å¾Œã§é‡è¦åº¦ã‚½ãƒ¼ãƒˆ
                    'reliability': 3,
                    'emotional': 1,
                    'reasoning': "å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å®Œäº†"
                })
            else:
                # ç¿»è¨³å¤±æ•—ã¾ãŸã¯å¯¾è±¡å¤–
                article.update({
                    'title': title,  # è‹±èªã®ã¾ã¾
                    'has_translation': False,
                    'importance': 3,
                    'reliability': 3,
                    'emotional': 1,
                    'reasoning': "ãƒãƒƒãƒç¿»è¨³å¤±æ•—ãƒ»è‹±èªåŸæ–‡" if ENABLE_BATCH_TRANSLATION else "ç¿»è¨³ç„¡åŠ¹ãƒ»è‹±èªåŸæ–‡"
                })
            
            analyzed_articles.append(article)
            
        except Exception as e:
            print(f"âš ï¸  å›½éš›è¨˜äº‹å‡¦ç†å¤±æ•—: {str(e)}")
            analyzed_articles.append(article)
    
    # ç¿»è¨³å¾Œã®é‡è¦åº¦ã‚½ãƒ¼ãƒˆï¼ˆå’Œè¨³ã‚’è¦‹ã¦åˆ¤æ–­å¯èƒ½ï¼‰
    if international_articles:
        print("ğŸ“Š ç¿»è¨³å¾Œé‡è¦åº¦ã‚½ãƒ¼ãƒˆå®Ÿè¡Œ...")
        important_keywords = ['trump', 'putin', 'ceasefire', 'nato', 'ukraine', 'israel', 'iran', 'election', 'war', 'summit', 
                             'ãƒˆãƒ©ãƒ³ãƒ—', 'ãƒ—ãƒ¼ãƒãƒ³', 'åœæˆ¦', 'NATO', 'ã‚¦ã‚¯ãƒ©ã‚¤ãƒŠ', 'ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«', 'ã‚¤ãƒ©ãƒ³', 'é¸æŒ™', 'æˆ¦äº‰', 'é¦–è„³ä¼šè«‡']
        
        # é‡è¦åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆåŸæ–‡ã¨å’Œè¨³ã®ä¸¡æ–¹ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
        for article in [a for a in analyzed_articles if a['is_international']]:
            score = 0
            title_text = (article['original_title'] + " " + article['title']).lower()
            
            for keyword in important_keywords:
                if keyword.lower() in title_text:
                    score += 3
            
            # ã‚¿ã‚¤ãƒˆãƒ«é•·ã«ã‚ˆã‚‹ã‚¹ã‚³ã‚¢
            if 20 <= len(article['title']) <= 100:
                score += 2
            
            # ç¿»è¨³æˆåŠŸã¯å„ªå…ˆ
            if article['has_translation']:
                score += 2
            
            # é‡è¦åº¦è¨­å®š
            if score >= 8:
                article['importance'] = 5
            elif score >= 5:
                article['importance'] = 4
            elif score >= 3:
                article['importance'] = 3
            else:
                article['importance'] = 2
        
        # é‡è¦åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        international_sorted = sorted([a for a in analyzed_articles if a['is_international']], 
                                    key=lambda x: (x['importance'], x['has_translation']), reverse=True)
        
        # analyzed_articlesã‚’æ›´æ–°
        analyzed_articles = [a for a in analyzed_articles if not a['is_international']] + international_sorted
    
    # å›½å†…è¨˜äº‹å‡¦ç†ï¼ˆç¿»è¨³ãªã—ï¼‰
    for article in domestic_articles:
        article.update({
            'title': article['original_title'],
            'has_translation': False,
            'importance': 3,
            'reliability': 3,
            'emotional': 1,
            'reasoning': "å›½å†…è¨˜äº‹"
        })
        analyzed_articles.append(article)
    
    print(f"âœ… å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å‡¦ç†å®Œäº†: {len(analyzed_articles)}ä»¶ï¼ˆç¿»è¨³{translation_count}ä»¶ãƒ»API{api_calls_used}å›ï¼‰")
    return analyzed_articles

# ======================================
# RSSå–å¾—æ©Ÿèƒ½
# ======================================

def fetch_rss_simple(source_name, url, max_items):
    """RSSè¨˜äº‹å–å¾—"""
    if not LIBS_AVAILABLE:
        return []
    
    try:
        print(f"ğŸ“¡ {source_name} ã‹ã‚‰å–å¾—ä¸­...")
        
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=15, verify=False)
        response.raise_for_status()
        
        from io import BytesIO
        feed = feedparser.parse(BytesIO(response.content))
        
        if not feed.entries:
            return []
        
        articles = []
        is_international = source_name not in [src[0] for src in JAPANESE_NEWS_SOURCES]
        
        for entry in feed.entries[:max_items * 2]:
            try:
                title = entry.title.strip() if hasattr(entry, 'title') else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"
                
                if any(keyword in title for keyword in EXCLUDE_KEYWORDS):
                    continue
                
                summary = ""
                if hasattr(entry, 'summary'):
                    summary = entry.summary
                elif hasattr(entry, 'description'):
                    summary = entry.description
                
                if summary:
                    summary = re.sub(r'<[^>]+>', '', summary)
                    summary = summary.strip()
                    if len(summary) > 120:
                        summary = summary[:120] + "..."
                
                link = entry.link if hasattr(entry, 'link') else ""
                tags = analyze_article_tags(title, summary)
                
                articles.append({
                    'title': title,
                    'original_title': title,
                    'summary': summary,
                    'url': link,
                    'source': source_name,
                    'tags': tags[:2],
                    'is_international': is_international,
                    'importance': 3,
                    'reliability': 3,
                    'emotional': 1,
                    'reasoning': "æœªå‡¦ç†"
                })
                
                if len(articles) >= max_items:
                    break
                    
            except Exception:
                continue
        
        print(f"âœ… {source_name}: {len(articles)}ä»¶å–å¾—å®Œäº†")
        return articles
        
    except Exception as e:
        print(f"âŒ {source_name} å–å¾—å¤±æ•—: {str(e)}")
        return []

def rule_based_select_articles(articles, target_count, is_international=False):
    """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹è¨˜äº‹çµã‚Šè¾¼ã¿"""
    if len(articles) <= target_count:
        return articles
    
    important_keywords = {
        'domestic': ['æ”¿åºœ', 'é¦–ç›¸', 'å¤§çµ±é ˜', 'é¸æŒ™', 'å›½ä¼š', 'çµŒæ¸ˆ', 'æ ªä¾¡', 'åœ°éœ‡', 'å°é¢¨', 'åŸç™º', 'æ–‡åŒ–', 'åœ°æ–¹', 'ç§‘å­¦'],
        'international': ['trump', 'putin', 'ukraine', 'israel', 'iran', 'nato', 'election', 'ceasefire', 'war', 'summit']
    }
    
    keyword_set = important_keywords['international' if is_international else 'domestic']
    
    scored_articles = []
    for article in articles:
        score = 0
        title_lower = article['title'].lower()
        
        for keyword in keyword_set:
            if keyword in title_lower:
                score += 3
        
        if 20 <= len(article['title']) <= 80:
            score += 2
        
        if len(article['summary']) > 50:
            score += 1
        
        # NHKã‚½ãƒ¼ã‚¹ã¯å„ªå…ˆ
        if "NHK" in article['source']:
            score += 2
        
        scored_articles.append((score, article))
    
    scored_articles.sort(key=lambda x: x[0], reverse=True)
    selected_articles = [article for score, article in scored_articles[:target_count]]
    
    return selected_articles

def remove_duplicates(articles):
    """è¨˜äº‹é‡è¤‡é™¤å»"""
    seen_titles = set()
    unique_articles = []
    
    for article in articles:
        title_words = set(article['title'].lower().split())
        is_duplicate = False
        
        for seen_title in seen_titles:
            seen_words = set(seen_title.lower().split())
            if len(title_words & seen_words) / len(title_words | seen_words) > 0.7:
                is_duplicate = True
                break
        
        if not is_duplicate:
            seen_titles.add(article['title'])
            unique_articles.append(article)
    
    return unique_articles

def get_all_news():
    """å…¨ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ï¼ˆå…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆï¼‰"""
    all_news = {'japanese': [], 'international': []}
    
    if not LIBS_AVAILABLE:
        return all_news
    
    print("ğŸ“° ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹å–å¾—é–‹å§‹ï¼ˆNHKå……å®Ÿãƒ»å…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆï¼‰...")
    
    # è¨˜äº‹å–å¾—
    for source_name, url, max_items in JAPANESE_NEWS_SOURCES:
        articles = fetch_rss_simple(source_name, url, max_items)
        all_news['japanese'].extend(articles)
        time.sleep(0.5)
    
    for source_name, url, max_items in INTERNATIONAL_NEWS_SOURCES:
        articles = fetch_rss_simple(source_name, url, max_items)
        all_news['international'].extend(articles)
        time.sleep(0.5)
    
    # é‡è¤‡é™¤å»
    all_news['japanese'] = remove_duplicates(all_news['japanese'])
    all_news['international'] = remove_duplicates(all_news['international'])
    
    print(f"ğŸ“Š è¨˜äº‹å–å¾—å®Œäº†: å›½å†…{len(all_news['japanese'])}ä»¶, å›½éš›{len(all_news['international'])}ä»¶")
    
    # ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹çµã‚Šè¾¼ã¿ï¼ˆå›½å†…45ä»¶ã«å¢—é‡ï¼‰
    selected_japanese = rule_based_select_articles(all_news['japanese'], 45, False)  # 45ä»¶ã«å¢—é‡
    selected_international = rule_based_select_articles(all_news['international'], 20, True)
    
    print(f"ğŸ¯ çµã‚Šè¾¼ã¿å®Œäº†: å›½å†…{len(selected_japanese)}ä»¶, å›½éš›{len(selected_international)}ä»¶")
    
    # å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å‡¦ç†
    final_articles = selected_japanese + selected_international
    final_analyzed = process_articles_simplified(final_articles)
    
    # çµæœåˆ†å‰²
    final_japanese = [a for a in final_analyzed if not a['is_international']]
    final_international = [a for a in final_analyzed if a['is_international']]
    
    print(f"âœ¨ å…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆå®Œæˆ: å›½å†…{len(final_japanese)}ä»¶, å›½éš›{len(final_international)}ä»¶")
    
    return {'japanese': final_japanese, 'international': final_international}

# ======================================
# APIæ©Ÿèƒ½ï¼ˆå¤©æ°—ãƒ»åè¨€ãƒ»æ­´å²ï¼‰
# ======================================

def get_api_quote():
    """APIçµŒç”±ã§è‹±èªåè¨€å–å¾—"""
    try:
        response = requests.get("https://api.quotable.io/random", timeout=10, verify=False)
        if response.status_code == 200:
            data = response.json()
            return {
                "quote": data.get("content", ""),
                "author": data.get("author", "Unknown"),
                "translation": ""
            }
    except Exception as e:
        print(f"âš ï¸  åè¨€APIå¤±æ•—: {str(e)}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    fallback_quotes = [
        {"quote": "The only way to do great work is to love what you do.", "author": "Steve Jobs"},
        {"quote": "Innovation distinguishes between a leader and a follower.", "author": "Steve Jobs"},
        {"quote": "The future belongs to those who believe in the beauty of their dreams.", "author": "Eleanor Roosevelt"},
    ]
    return random.choice(fallback_quotes)

def get_api_history():
    """APIçµŒç”±ã§ä»Šæ—¥ã¯ä½•ã®æ—¥å–å¾—"""
    try:
        today = date.today()
        url = f"http://history.muffinlabs.com/date/{today.month}/{today.day}"
        response = requests.get(url, timeout=10, verify=False)
        
        if response.status_code == 200:
            data = response.json()
            events = data.get("data", {}).get("Events", [])
            
            if events:
                selected_event = events[0]
                year = selected_event.get("year", "")
                text = selected_event.get("text", "")
                return f"{year} - {text[:150]}{'...' if len(text) > 150 else ''}"
        
    except Exception as e:
        print(f"âš ï¸  æ­´å²APIå¤±æ•—: {str(e)}")
    
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    today = date.today()
    return f"{today.month}æœˆ{today.day}æ—¥ - ä»Šæ—¥ã¨ã„ã†æ—¥ã¯äºŒåº¦ã¨æ¥ãªã„ç‰¹åˆ¥ãªæ—¥ã§ã™ã€‚"

def get_weather_data():
    """å¤©æ°—ãƒ‡ãƒ¼ã‚¿å–å¾—"""
    if not LIBS_AVAILABLE:
        return get_fallback_weather()
    
    try:
        url = "https://api.open-meteo.com/v1/forecast"
        params = {
            'latitude': LATITUDE,
            'longitude': LONGITUDE,
            'hourly': 'temperature_2m,weather_code',
            'daily': 'temperature_2m_max,temperature_2m_min,weather_code',
            'timezone': 'Asia/Tokyo',
            'forecast_days': 3
        }
        
        response = requests.get(url, params=params, timeout=15, verify=False)
        response.raise_for_status()
        data = response.json()
        
        weather_codes = {
            0: "å¿«æ™´", 1: "æ™´ã‚Œ", 2: "éƒ¨åˆ†çš„ã«æ›‡ã‚Š", 3: "æ›‡ã‚Š",
            45: "éœ§", 48: "éœ§æ°·", 51: "å°é›¨", 53: "é›¨", 55: "å¼·é›¨",
            61: "é›¨", 63: "é›¨", 65: "å¼·é›¨", 71: "é›ª", 73: "é›ª", 75: "å¤§é›ª",
            80: "ã«ã‚ã‹é›¨", 95: "é›·é›¨"
        }
        
        now_hour = min(datetime.now().hour, len(data['hourly']['temperature_2m']) - 1)
        current_temp = round(data['hourly']['temperature_2m'][now_hour])
        current_code = data['hourly']['weather_code'][now_hour]
        current_weather = weather_codes.get(current_code, "ä¸æ˜")
        
        weekly_forecast = []
        days = ["ä»Šæ—¥", "æ˜æ—¥", "æ˜å¾Œæ—¥"]
        for i in range(3):
            max_temp = round(data['daily']['temperature_2m_max'][i])
            min_temp = round(data['daily']['temperature_2m_min'][i])
            code = data['daily']['weather_code'][i]
            weather_desc = weather_codes.get(code, "ä¸æ˜")
            weekly_forecast.append({
                'date': days[i],
                'high': f"{max_temp}Â°C",
                'low': f"{min_temp}Â°C",
                'weather': weather_desc
            })
        
        return {
            'current_temp': f"{current_temp}Â°C",
            'current_weather': current_weather,
            'weekly': weekly_forecast
        }
        
    except Exception as e:
        print(f"âš ï¸  å¤©æ°—APIå¤±æ•—: {str(e)}")
        return get_fallback_weather()

def get_fallback_weather():
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤©æ°—"""
    return {
        'current_temp': "15Â°C",
        'current_weather': "æ™´ã‚Œ",
        'weekly': [
            {'date': 'ä»Šæ—¥', 'high': '20Â°C', 'low': '8Â°C', 'weather': 'æ™´ã‚Œ'},
            {'date': 'æ˜æ—¥', 'high': '22Â°C', 'low': '10Â°C', 'weather': 'æ›‡ã‚Š'},
            {'date': 'æ˜å¾Œæ—¥', 'high': '19Â°C', 'low': '9Â°C', 'weather': 'é›¨'}
        ]
    }

# ======================================
# ãƒãƒƒã‚¸æ©Ÿèƒ½
# ======================================

def get_importance_badge(score):
    """é‡è¦åº¦ãƒãƒƒã‚¸"""
    badges = {
        5: {"icon": "ğŸ”¥", "text": "æœ€é‡è¦", "color": "#d32f2f"},
        4: {"icon": "âš¡", "text": "é‡è¦", "color": "#f57c00"},
        3: {"icon": "ğŸ“°", "text": "ä¸€èˆ¬", "color": "#1976d2"},
        2: {"icon": "ğŸ“", "text": "åœ°åŸŸ", "color": "#388e3c"},
        1: {"icon": "ğŸ’¬", "text": "è»½å¾®", "color": "#616161"}
    }
    return badges.get(score, badges[3])

def get_reliability_badge(score):
    """ä¿¡é ¼åº¦ãƒãƒƒã‚¸"""
    badges = {
        5: {"icon": "âœ…", "text": "ç¢ºå®Ÿ", "color": "#2e7d32"},
        4: {"icon": "ğŸ”", "text": "ä¿¡é ¼", "color": "#388e3c"},
        3: {"icon": "ğŸ“‹", "text": "ä¸€èˆ¬", "color": "#1976d2"},
        2: {"icon": "âš ï¸", "text": "è¦ç¢ºèª", "color": "#f57c00"},
        1: {"icon": "â“", "text": "ä¸ç¢ºå®Ÿ", "color": "#d32f2f"}
    }
    return badges.get(score, badges[3])

def get_emotional_badge(score):
    """æ„Ÿæƒ…åº¦ãƒãƒƒã‚¸"""
    badges = {
        1: {"icon": "ğŸ“Š", "text": "å®¢è¦³çš„", "color": "#1976d2"},
        2: {"icon": "ğŸ’­", "text": "ä¸»è¦³çš„", "color": "#f57c00"},
        3: {"icon": "ğŸ’¢", "text": "æ„Ÿæƒ…çš„", "color": "#d32f2f"}
    }
    return badges.get(score, badges[1])

def get_priority_background(index, total_count):
    """å„ªå…ˆåº¦åˆ¥èƒŒæ™¯è‰²"""
    if index < 3:
        return "#fff3e0"  # ã‚ªãƒ¬ãƒ³ã‚¸ç³»ï¼ˆä¸Šä½3ä»¶ï¼‰
    elif index < 10:
        return "#f3e5f5"  # ç´«ç³»ï¼ˆä¸Šä½10ä»¶ï¼‰
    else:
        return "#fafafa"  # ã‚°ãƒ¬ãƒ¼ç³»ï¼ˆãã®ä»–ï¼‰

# ======================================
# HTMLç”Ÿæˆï¼ˆå„ªå…ˆåº¦åˆ¥èƒŒæ™¯è‰²ç‰ˆï¼‰
# ======================================

def generate_nhk_style_newspaper():
    """NHKã‚¹ã‚¿ã‚¤ãƒ«æ–°èHTMLç”Ÿæˆ"""
    today = date.today()
    now = datetime.now()
    
    print("ğŸ“° NHKã‚¹ã‚¿ã‚¤ãƒ«æ–°èç”Ÿæˆä¸­...")
    
    quote = get_api_quote()
    history = get_api_history()
    weather = get_weather_data()
    news = get_all_news()
    
    weekdays = ["æœˆæ›œæ—¥", "ç«æ›œæ—¥", "æ°´æ›œæ—¥", "æœ¨æ›œæ—¥", "é‡‘æ›œæ—¥", "åœŸæ›œæ—¥", "æ—¥æ›œæ—¥"]
    weekday_jp = weekdays[today.weekday()]
    
    html = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è - {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}</title>
    <style>
        body {{
            font-family: 'Hiragino Sans', 'Yu Gothic', 'Meiryo', sans-serif;
            font-size: 16px;
            line-height: 1.7;
            max-width: 1000px;
            margin: 0 auto;
            padding: 15px;
            background-color: #fff;
            color: #333;
        }}
        .header {{
            background: #003f7f;
            color: white;
            padding: 20px;
            margin-bottom: 20px;
            border-radius: 5px;
        }}
        .header h1 {{
            margin: 0;
            font-size: 28px;
            font-weight: bold;
        }}
        .header .date {{
            margin: 8px 0 0 0;
            font-size: 18px;
        }}
        .info-bar {{
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
            margin-bottom: 25px;
        }}
        .info-box {{
            background: #f5f5f5;
            padding: 15px;
            border-radius: 5px;
            border-left: 4px solid #003f7f;
        }}
        .info-box h3 {{
            margin: 0 0 10px 0;
            font-size: 16px;
            color: #003f7f;
            font-weight: bold;
        }}
        .weather-mini {{
            display: flex;
            justify-content: space-between;
            font-size: 14px;
        }}
        .weather-day {{
            text-align: center;
        }}
        .quote-text {{
            font-size: 14px;
            font-style: italic;
            color: #555;
        }}
        .main-content {{
            display: grid;
            grid-template-columns: 2fr 1fr;
            gap: 25px;
        }}
        .news-section {{
            background: white;
        }}
        .news-title {{
            font-size: 22px;
            font-weight: bold;
            color: #003f7f;
            margin: 0 0 15px 0;
            padding-bottom: 8px;
            border-bottom: 3px solid #003f7f;
        }}
        .news-item {{
            margin-bottom: 20px;
            padding: 15px;
            border: 1px solid #ddd;
            border-radius: 5px;
        }}
        .priority-top3 {{
            background: #fff3e0;
            border-left: 4px solid #ff9800;
        }}
        .priority-top10 {{
            background: #f3e5f5;
            border-left: 4px solid #9c27b0;
        }}
        .priority-others {{
            background: #fafafa;
        }}
        .news-tags {{
            margin-bottom: 8px;
        }}
        .tag {{
            display: inline-block;
            background: #e1f5fe;
            color: #0277bd;
            padding: 2px 8px;
            border-radius: 10px;
            font-size: 12px;
            margin-right: 5px;
        }}
        .ai-badges {{
            display: flex;
            gap: 5px;
            margin-bottom: 8px;
            flex-wrap: wrap;
        }}
        .ai-badge {{
            display: inline-block;
            padding: 2px 6px;
            border-radius: 8px;
            font-size: 11px;
            font-weight: bold;
            color: white;
        }}
        .original-title {{
            font-size: 12px;
            color: #888;
            font-style: italic;
            margin-bottom: 4px;
            background: #f0f0f0;
            padding: 5px;
            border-radius: 3px;
        }}
        .translation-note {{
            font-size: 11px;
            color: #666;
            margin-bottom: 4px;
        }}
        .news-headline {{
            font-size: 16px;
            font-weight: bold;
            margin: 8px 0;
            line-height: 1.4;
        }}
        .news-headline a {{
            color: #333;
            text-decoration: none;
        }}
        .news-headline a:hover {{
            color: #003f7f;
            text-decoration: underline;
        }}
        .news-summary {{
            font-size: 14px;
            color: #666;
            margin: 8px 0;
        }}
        .news-source {{
            font-size: 12px;
            color: #888;
        }}
        .sidebar {{
            background: #f8f9fa;
            padding: 15px;
            border-radius: 5px;
        }}
        .sidebar h3 {{
            color: #003f7f;
            font-size: 16px;
            margin: 0 0 10px 0;
            border-bottom: 2px solid #003f7f;
            padding-bottom: 5px;
        }}
        .sidebar-content {{
            font-size: 14px;
            line-height: 1.6;
        }}
        .stats-item {{
            display: flex;
            justify-content: space-between;
            margin: 5px 0;
            padding: 5px 0;
            border-bottom: 1px dotted #ccc;
        }}
        .footer {{
            background: #003f7f;
            color: white;
            text-align: center;
            padding: 15px;
            margin-top: 30px;
            border-radius: 5px;
        }}
        .note {{
            background: #fff3cd;
            border: 1px solid #ffeaa7;
            padding: 10px;
            margin: 15px 0;
            border-radius: 5px;
            font-size: 14px;
            color: #856404;
        }}
        .success {{
            background: #d4edda;
            border: 1px solid #c3e6cb;
            color: #155724;
        }}
        .priority-legend {{
            background: #e3f2fd;
            border: 1px solid #bbdefb;
            padding: 10px;
            margin: 15px 0;
            border-radius: 5px;
            font-size: 13px;
        }}
        @media (max-width: 768px) {{
            .main-content {{
                grid-template-columns: 1fr;
            }}
            .info-bar {{
                grid-template-columns: 1fr;
            }}
        }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ“° ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è</h1>
        <div class="date">{today.strftime('%Yå¹´%mæœˆ%dæ—¥')} ({weekday_jp})</div>
    </div>

    <div class="info-bar">
        <div class="info-box">
            <h3>ğŸŒ¤ï¸ {LOCATION_NAME}ã®å¤©æ°—</h3>
            <div style="text-align: center; margin-bottom: 10px;">
                <strong>{weather['current_temp']} {weather['current_weather']}</strong>
            </div>
            <div class="weather-mini">"""

    for item in weather['weekly']:
        html += f"""
                <div class="weather-day">
                    <div style="font-weight: bold;">{item['date']}</div>
                    <div>{item['high']}/{item['low']}</div>
                    <div style="font-size: 12px;">{item['weather']}</div>
                </div>"""

    html += f"""
            </div>
        </div>
        
        <div class="info-box">
            <h3>ğŸ“š ä»Šæ—¥ã¯ä½•ã®æ—¥</h3>
            <div style="font-size: 14px; line-height: 1.5;">
                {history[:120]}{'...' if len(history) > 120 else ''}
            </div>
        </div>
        
        <div class="info-box">
            <h3>ğŸ’­ ä»Šæ—¥ã®è¨€è‘‰</h3>
            <div class="quote-text">
                "{quote['quote'][:70]}{'...' if len(quote['quote']) > 70 else ''}"
                <div style="text-align: right; margin-top: 5px; font-weight: bold;">
                    â€” {quote['author']}
                </div>
            </div>
        </div>
    </div>

    <div class="main-content">
        <div class="news-section">
            <h2 class="news-title">ğŸ‡¯ğŸ‡µ å›½å†…ãƒ‹ãƒ¥ãƒ¼ã‚¹</h2>
            <div class="note success">
                âœ… NHKå……å®Ÿç‰ˆã‹ã‚‰{len(news['japanese'])}ä»¶ã‚’å³é¸å–å¾—ãƒ»é‡è¦åº¦åˆ¥è¡¨ç¤º
            </div>
            <div class="priority-legend">
                ğŸ”¶ <strong>ã‚ªãƒ¬ãƒ³ã‚¸èƒŒæ™¯</strong>: ä¸Šä½3ä»¶ | ğŸ’œ <strong>ç´«èƒŒæ™¯</strong>: ä¸Šä½10ä»¶ | âšª <strong>ç™½èƒŒæ™¯</strong>: ãã®ä»–
            </div>"""

    # å›½å†…ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆå„ªå…ˆåº¦åˆ¥èƒŒæ™¯è‰²ï¼‰
    for i, article in enumerate(news['japanese']):
        importance_badge = get_importance_badge(article['importance'])
        reliability_badge = get_reliability_badge(article['reliability'])
        emotional_badge = get_emotional_badge(article['emotional'])
        
        # å„ªå…ˆåº¦åˆ¥CSSã‚¯ãƒ©ã‚¹
        if i < 3:
            priority_class = "priority-top3"
        elif i < 10:
            priority_class = "priority-top10"
        else:
            priority_class = "priority-others"
        
        html += f"""
            <div class="news-item {priority_class}">
                <div class="news-tags">
                    {''.join([f'<span class="tag">{tag["icon"]} {tag["name"]}</span>' for tag in article["tags"]])}
                </div>
                <div class="ai-badges">
                    <span class="ai-badge" style="background: {importance_badge['color']}">
                        {importance_badge['icon']} {importance_badge['text']}
                    </span>
                    <span class="ai-badge" style="background: {reliability_badge['color']}">
                        {reliability_badge['icon']} {reliability_badge['text']}
                    </span>
                    <span class="ai-badge" style="background: {emotional_badge['color']}">
                        {emotional_badge['icon']} {emotional_badge['text']}
                    </span>
                </div>
                <div class="news-headline">
                    <a href="{article['url']}" target="_blank">{article['title']}</a>
                </div>
                <div class="news-summary">{article['summary']}</div>
                <div class="news-source">å‡ºå…¸: {article['source']} | å‡¦ç†: {article['reasoning']}</div>
            </div>"""

    # å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹çµ±è¨ˆï¼ˆå…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆï¼‰
    batch_translated = [a for a in news['international'] if "å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å®Œäº†" in a['reasoning']]
    english_only = [a for a in news['international'] if "è‹±èªåŸæ–‡" in a['reasoning']]
    
    if ENABLE_BATCH_TRANSLATION:
        translation_status = f"å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å¯¾å¿œï¼ˆæœ€å¤§{MAX_BATCH_SIZE}ä»¶ãƒ»1å›ã®APIå‘¼ã³å‡ºã—ï¼‰"
        if batch_translated:
            legend_text = f"ğŸš€ <strong>å…¨ä»¶ãƒãƒƒãƒç¿»è¨³æ¸ˆã¿</strong>: {len(batch_translated)}ä»¶ | ğŸ‡¬ğŸ‡§ <strong>è‹±èªåŸæ–‡</strong>: {len(english_only)}ä»¶"
        else:
            legend_text = f"ğŸ‡¬ğŸ‡§ <strong>å…¨ã¦è‹±èªåŸæ–‡</strong>: {len(news['international'])}ä»¶ï¼ˆãƒãƒƒãƒç¿»è¨³å¤±æ•—ï¼‰"
    else:
        translation_status = "ç¿»è¨³æ©Ÿèƒ½ç„¡åŠ¹"
        legend_text = f"ğŸ‡¬ğŸ‡§ <strong>å…¨ã¦è‹±èªåŸæ–‡</strong>: {len(news['international'])}ä»¶ï¼ˆç¿»è¨³æ©Ÿèƒ½ç„¡åŠ¹ï¼‰"
    
    html += f"""
            <h2 class="news-title">ğŸŒ å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹</h2>
            <div class="note success">
                âœ… æµ·å¤–ãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰{len(news['international'])}ä»¶ã‚’å–å¾—ãƒ»{translation_status}
            </div>
            <div class="priority-legend">
                {legend_text} | ğŸ“Š ç¿»è¨³å¾Œé‡è¦åº¦ã‚½ãƒ¼ãƒˆæ¸ˆã¿
            </div>"""

    # å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆå…¨ä»¶ç¿»è¨³å¯¾å¿œç‰ˆï¼‰
    for i, article in enumerate(news['international']):
        importance_badge = get_importance_badge(article['importance'])
        reliability_badge = get_reliability_badge(article['reliability'])
        emotional_badge = get_emotional_badge(article['emotional'])
        
        # é‡è¦åº¦ã«å¿œã˜ãŸã‚¯ãƒ©ã‚¹
        if article['importance'] >= 4:
            priority_class = "priority-top3"  # é«˜é‡è¦åº¦
        elif i < 10:
            priority_class = "priority-top10"
            
        else:
            priority_class = "priority-others"
        
        # ç¿»è¨³ãŒã‚ã‚‹ã‹ã©ã†ã‹
        has_translation = article.get('has_translation', False)
        
        html += f"""
            <div class="news-item {priority_class}">
                <div class="news-tags">
                    {''.join([f'<span class="tag">{tag["icon"]} {tag["name"]}</span>' for tag in article["tags"]])}
                </div>
                <div class="ai-badges">
                    <span class="ai-badge" style="background: {importance_badge['color']}">
                        {importance_badge['icon']} {importance_badge['text']}
                    </span>
                    <span class="ai-badge" style="background: {reliability_badge['color']}">
                        {reliability_badge['icon']} {reliability_badge['text']}
                    </span>
                    <span class="ai-badge" style="background: {emotional_badge['color']}">
                        {emotional_badge['icon']} {emotional_badge['text']}
                    </span>
                </div>
                <div class="original-title">ã€åŸæ–‡ã€‘ {article["original_title"]}</div>
                <div class="news-headline">
                    <a href="{article['url']}" target="_blank">
                        {"ã€å’Œè¨³ã€‘ " + article['title'] if has_translation else "ã€è‹±èªã€‘ " + article['title']}
                    </a>
                </div>
                <div class="news-summary">{article['summary']}</div>
                <div class="news-source">å‡ºå…¸: {article['source']} | å‡¦ç†: {article['reasoning']}</div>
            </div>"""

    # çµ±è¨ˆæƒ…å ±
    all_tags = {}
    for article in news['japanese'] + news['international']:
        for tag in article['tags']:
            tag_name = tag['name']
            all_tags[tag_name] = all_tags.get(tag_name, 0) + 1
    
    sorted_tags = sorted(all_tags.items(), key=lambda x: x[1], reverse=True)[:5]

    html += f"""
        </div>
        
        <div class="sidebar">
            <h3>ğŸ“Š ä»Šæ—¥ã®è¨˜äº‹åˆ†æ</h3>
            <div class="sidebar-content">
                <div class="stats-item">
                    <span><strong>ç·è¨˜äº‹æ•°</strong></span>
                    <span><strong>{len(news['japanese']) + len(news['international'])}ä»¶</strong></span>
                </div>
                <div class="stats-item">
                    <span>å›½å†…ãƒ‹ãƒ¥ãƒ¼ã‚¹</span>
                    <span>{len(news['japanese'])}ä»¶</span>
                </div>
                <div class="stats-item">
                    <span>å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹</span>
                    <span>{len(news['international'])}ä»¶</span>
                </div>"""
    
    # ç¿»è¨³çµ±è¨ˆï¼ˆå…¨ä»¶ãƒãƒƒãƒç¿»è¨³ç‰ˆï¼‰
    if ENABLE_BATCH_TRANSLATION:
        html += f"""
                <hr style="margin: 15px 0;">
                <h4 style="margin: 10px 0; color: #003f7f;">å…¨ä»¶ãƒãƒƒãƒç¿»è¨³å‡¦ç†</h4>
                <div class="stats-item">
                    <span>ğŸš€ å…¨ä»¶ç¿»è¨³æ¸ˆã¿</span>
                    <span>{len(batch_translated)}ä»¶</span>
                </div>
                <div class="stats-item">
                    <span>ğŸ‡¬ğŸ‡§ è‹±èªåŸæ–‡</span>
                    <span>{len(english_only)}ä»¶</span>
                </div>
                <div class="stats-item">
                    <span>ğŸ“¡ APIå‘¼ã³å‡ºã—</span>
                    <span>{"1å›" if batch_translated else "0å›"}</span>
                </div>
                <div class="stats-item">
                    <span>ğŸ“Š å‡¦ç†åŠ¹ç‡</span>
                    <span>å…¨{len(news['international'])}ä»¶â†’1å›</span>
                </div>"""
    
    html += f"""
                <hr style="margin: 15px 0;">
                <h4 style="margin: 10px 0; color: #003f7f;">ä¸»è¦ã‚«ãƒ†ã‚´ãƒª</h4>"""
    
    for tag_name, count in sorted_tags:
        html += f"""
                <div class="stats-item">
                    <span>{tag_name}</span>
                    <span>{count}ä»¶</span>
                </div>"""

    html += f"""
                <hr style="margin: 15px 0;">
                <p style="font-size: 13px; color: #666;">
                    NHKå……å®Ÿç‰ˆã§å›½å†…45ä»¶ã‚’å³é¸ã€‚{f"æµ·å¤–å…¨{len(news['international'])}ä»¶ã‚’ä¸€æ‹¬ãƒãƒƒãƒç¿»è¨³ï¼ˆ1å›ã®APIå‘¼ã³å‡ºã—ï¼‰å¾Œã€é‡è¦åº¦ã‚½ãƒ¼ãƒˆã€‚" if ENABLE_BATCH_TRANSLATION else "æµ·å¤–ãƒ‹ãƒ¥ãƒ¼ã‚¹ã¯è‹±èªåŸæ–‡ã§è¡¨ç¤ºã€‚"}
                    å…¨è¨˜äº‹ã§åŸæ–‡ãƒ»å’Œè¨³ä½µè¨˜ã€‚å„ªå…ˆåº¦åˆ¥èƒŒæ™¯è‰²ã§è¦‹ã‚„ã™ã•å‘ä¸Šã€‚
                </p>
            </div>
        </div>
    </div>

    <div class="footer">
        <p><strong>ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è | ç™ºè¡Œ: {SENDER_NAME} | ç™ºè¡Œæ—¥æ™‚: {now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}</strong></p>
    </div>
</body>
</html>"""
    
    return html

# ======================================
# ãƒ¡ãƒ¼ãƒ«é€ä¿¡
# ======================================

def send_email(html_content):
    """ãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
    today = date.today()
    subject = f"ğŸ“° ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è - {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
    
    try:
        msg = MIMEMultipart('alternative')
        msg['Subject'] = subject
        msg['From'] = SENDER_EMAIL
        msg['To'] = ", ".join(RECIPIENTS)
        
        html_part = MIMEText(html_content, 'html', 'utf-8')
        msg.attach(html_part)
        
        server = smtplib.SMTP('smtp.gmail.com', 587)
        server.starttls()
        server.login(SENDER_EMAIL, SENDER_PASSWORD)
        
        for recipient in RECIPIENTS:
            server.send_message(msg, to_addrs=[recipient])
            print(f"âœ… ãƒ¡ãƒ¼ãƒ«é€ä¿¡å®Œäº†: {recipient}")
        
        server.quit()
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print(f"ğŸ“° ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°èç”Ÿæˆé–‹å§‹")
    print(f"ğŸ“… ç™ºè¡Œæ—¥: {date.today().strftime('%Yå¹´%mæœˆ%dæ—¥')}")
    
    if not LIBS_AVAILABLE:
        print("âŒ pip install feedparser requests google-generativeai ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return
    
    # HTMLç”Ÿæˆ
    html_content = generate_nhk_style_newspaper()
    
    # ãƒ¡ãƒ¼ãƒ«é€ä¿¡
    print("\nğŸ“§ æ–°èé…ä¿¡ä¸­...")
    success = send_email(html_content)
    
    if success:
        print("ğŸ‰ æ–°èé…ä¿¡å®Œäº†ï¼")
    else:
        print("âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¤±æ•—")
    
    print(f"\nğŸš€ å…¨ä»¶ãƒãƒƒãƒç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ :")
    if ENABLE_BATCH_TRANSLATION:
        print(f"ğŸŒ å…¨ä»¶ãƒãƒƒãƒç¿»è¨³: æµ·å¤–å…¨20ä»¶ã‚’1å›ã®APIå‘¼ã³å‡ºã—ã§å‡¦ç†")
        print(f"ğŸ“¡ APIåŠ¹ç‡: å¾“æ¥ã®20å› â†’ 1å›ï¼ˆ20å€åŠ¹ç‡åŒ–ï¼‰")
        print(f"ğŸ“Š ç¿»è¨³å¾Œã‚½ãƒ¼ãƒˆ: å’Œè¨³ã‚’è¦‹ã¦é‡è¦åº¦åˆ¤å®šâ†’ä¸¦ã³æ›¿ãˆ")
        print(f"ğŸ“– å…¨ä»¶ä½µè¨˜: å…¨è¨˜äº‹ã§ã€åŸæ–‡ã€‘ã€å’Œè¨³ã€‘è¡¨ç¤º")
    else:
        print(f"ğŸŒ å…¨ä»¶ãƒãƒƒãƒç¿»è¨³: ç„¡åŠ¹ï¼ˆå…¨ã¦åŸæ–‡è¡¨ç¤ºï¼‰")
    print(f"ğŸ“° NHKå……å®Ÿç‰ˆ: åœ°æ–¹ãƒ»æ–‡åŒ–ãƒ»ã‚¹ãƒãƒ¼ãƒ„ãƒ»ç½å®³å«ã‚€")
    print(f"ğŸ“Š å›½å†…è¨˜äº‹: 45ä»¶")
    print(f"ğŸ¨ å„ªå…ˆåº¦è¡¨ç¤º: é‡è¦åº¦4ä»¥ä¸Šãƒ»ä¸Šä½10ä»¶ã§èƒŒæ™¯è‰²å¤‰æ›´")
    print(f"âŒ Yahooå‰Šé™¤: NHKä¸­å¿ƒã®ä¿¡é ¼æ€§é‡è¦–")

if __name__ == "__main__":
    main()

