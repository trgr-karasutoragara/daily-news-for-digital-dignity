# =============================================================================
# SYNTAX ERROR FIXES - 2025/6/27
# =============================================================================
# This script had multiple syntax errors that prevented execution:
#
# PROBLEMS IDENTIFIED:
# - Invalid Unicode characters: em/en dashes (U+2013, U+2014) and 
#   non-breaking spaces (U+00A0) instead of regular characters
# - Unterminated string literals: missing closing quotes in SENDER_NAME, 
#   User-Agent headers, and f-strings
# - Incomplete syntax: unfinished if expressions, missing else clauses,
#   and unassigned variables (LATITUDE, LONGITUDE)
# - Multi-line f-string breaks causing "unterminated f-string literal" errors
# - Function name typos: 'printf' instead of 'print'
# - Incorrect escape sequences in formatted strings
#
# FIXES APPLIED:
# - Replaced all Unicode dashes with standard hyphens (-)
# - Replaced non-breaking spaces (U+00A0) with regular spaces
# - Added proper string termination and placeholder values
# - Completed conditional expressions with proper else clauses
# - Consolidated multi-line f-strings into single lines
# - Corrected function names and escape sequences
# - Added proper indentation using tabs consistently
#
# RESULT: All syntax errors resolved, script now executes successfully
# =============================================================================


## Background

This project was originally developed as a personalized news generator  
to support the digital dignity of an elderly woman born in 1947.  

For those interested in the deeper ethical, social, and philosophical motivations  
behind this project, please refer to the following **speech-style draft**:  

**[AI and Elderly Dignity: A Speech Draft for Researchers](https://www.academia.edu/129405187/AI_and_Elderly_Dignity)**  
by Trgr KarasuToragara (2025)  

This is not a technical paper, but a narrative crafted to bridge abstract AI ethics  
with lived realitiesâ€”especially in the context of aging, care work, and autonomy.


# This script was originally created for my mother, born in 1947,
# to help her access reliable news sources with freedom of choice.
# While it is recommended to separate configuration files,
# I have kept everything in a single script for simplicity due to its small scale.
# Some comments remain in Japanese for clarity and maintainability on my side.



#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è - ä¿®æ­£ç‰ˆ
"""

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from datetime import datetime, date
import random
import time
import re
import json
import ssl
import urllib3

# å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒª
try:
	import feedparser
	import requests
	LIBS_AVAILABLE = True
except ImportError:
	LIBS_AVAILABLE = False
	print("âŒ å¿…é ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¸è¶³: pip install feedparser requests")

# SSLè­¦å‘Šã‚’ç„¡åŠ¹åŒ–ï¼ˆè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
ssl._create_default_https_context = ssl._create_unverified_context

# ======================================
# è¨­å®šã‚¨ãƒªã‚¢
# ======================================

SENDER_EMAIL = "your_email@gmail.com"
SENDER_PASSWORD = "your_app_password"
RECIPIENTS = ["recipient1@example.com", "recipient2@example.com"]
SENDER_NAME = "ãƒˆãƒ©ã‚¬ãƒ©æ–°èç¤¾"
LOCATION_NAME = "æ±äº¬"
LATITUDE = "35.6762"
LONGITUDE = "139.6503"

# ======================================
# APIè¨­å®š
# ======================================

# ä»Šæ—¥ã¯ä½•ã®æ—¥API
HISTORY_API_URL = "http://history.muffinlabs.com/date"

# è‹±èªåè¨€APIï¼ˆãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä»˜ãï¼‰
QUOTE_API_URLS = [
	"https://api.quotable.io/random",
	"https://zenquotes.io/api/random",
	"https://api.quotegarden.com/quotes/random"
]

# ======================================
# ã‚¿ã‚°åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
# ======================================

ARTICLE_CATEGORIES = {
	"æ”¿æ²»ãƒ»å¤–äº¤": {
		"icon": "ğŸ›ï¸",
		"keywords": ["election", "government", "president", "minister", "parliament", "congress", "summit", "diplomacy", "vote", "policy", "leader", "official", "political", "democracy", "campaign", "referendum", "æ”¿æ²»", "å¤–äº¤", "é¦–ç›¸", "å¤§çµ±é ˜", "å›½ä¼š", "é¸æŒ™", "æ”¿åºœ"]
	},
	"ç´›äº‰ãƒ»è»äº‹": {
		"icon": "âš”ï¸",
		"keywords": ["war", "conflict", "military", "attack", "bombing", "missile", "drone", "army", "navy", "defense", "weapons", "soldiers", "battle", "invasion", "ceasefire", "terrorism", "security", "forces", "æˆ¦äº‰", "è»äº‹", "æ”»æ’ƒ", "ãƒŸã‚µã‚¤ãƒ«", "è‡ªè¡›éšŠ", "é˜²è¡›", "åœæˆ¦", "ãƒ†ãƒ­"]
	},
	"çµŒæ¸ˆãƒ»å¸‚å ´": {
		"icon": "ğŸ’¹",
		"keywords": ["economy", "market", "trade", "business", "company", "financial", "bank", "investment", "GDP", "inflation", "recession", "stock", "currency", "oil", "gas", "energy", "industry", "growth", "çµŒæ¸ˆ", "å¸‚å ´", "æ ªä¾¡", "æŠ•è³‡", "é‡‘è", "ä¼æ¥­", "æ¥­ç¸¾", "æ™¯æ°—"]
	},
	"ç’°å¢ƒãƒ»æ°—å€™": {
		"icon": "ğŸŒ",
		"keywords": ["climate", "environment", "global warming", "renewable", "carbon", "pollution", "green", "sustainability", "biodiversity", "conservation", "eco", "solar", "wind", "emissions", "nature", "ç’°å¢ƒ", "æ°—å€™", "æ¸©æš–åŒ–", "è„±ç‚­ç´ ", "å†ç”Ÿå¯èƒ½", "ã‚¨ã‚³"]
	},
	"ç¤¾ä¼šãƒ»æ–‡åŒ–": {
		"icon": "ğŸ‘¥",
		"keywords": ["society", "social", "community", "education", "school", "university", "culture", "religion", "family", "youth", "elderly", "women", "gender", "rights", "protest", "demonstration", "ç¤¾ä¼š", "æ•™è‚²", "å­¦æ ¡", "æ–‡åŒ–", "å®—æ•™", "æ¨©åˆ©", "æŠ—è­°"]
	},
	"ç§‘å­¦ãƒ»æŠ€è¡“": {
		"icon": "ğŸ”¬",
		"keywords": ["science", "technology", "research", "AI", "computer", "internet", "cyber", "space", "satellite", "innovation", "discovery", "study", "experiment", "data", "digital", "ç§‘å­¦", "æŠ€è¡“", "ç ”ç©¶", "AI", "å®‡å®™", "IT", "ãƒ‡ã‚¸ã‚¿ãƒ«", "å®Ÿé¨“"]
	},
	"å¥åº·ãƒ»åŒ»ç™‚": {
		"icon": "ğŸ¥",
		"keywords": ["health", "medical", "hospital", "doctor", "patient", "disease", "virus", "pandemic", "treatment", "vaccine", "medicine", "healthcare", "mental health", "outbreak", "surgery", "å¥åº·", "åŒ»ç™‚", "ç—…é™¢", "åŒ»å¸«", "æ‚£è€…", "ã‚¦ã‚¤ãƒ«ã‚¹", "æ²»ç™‚", "ãƒ¯ã‚¯ãƒãƒ³"]
	},
	"ç½å®³ãƒ»äº‹æ•…": {
		"icon": "ğŸš¨",
		"keywords": ["earthquake", "tsunami", "flood", "fire", "hurricane", "tornado", "disaster", "emergency", "accident", "crash", "explosion", "rescue", "evacuation", "damage", "victims", "alert", "åœ°éœ‡", "æ´¥æ³¢", "ç«ç½", "ç½å®³", "äº‹æ•…", "ç·Šæ€¥", "é¿é›£", "è¢«å®³"]
	}
}

# ======================================
# è±¡å¾´çš„ç¿»è¨³ã‚·ã‚¹ãƒ†ãƒ 
# ======================================

TRANSLATION_PATTERNS = {
	# æ”¿æ²»ãƒ»ä¼šè«‡
	r"(\w+)\s+leaders?\s+meet": r"\1é¦–è„³ä¼šè«‡",
	r"(\w+)\s+summit": r"\1ã‚µãƒŸãƒƒãƒˆ",
	r"(\w+)\s+talks": r"\1å”è­°",
	r"peace\s+negotiations": "å’Œå¹³äº¤æ¸‰",
	r"trade\s+agreement": "è²¿æ˜“å”å®š",
	r"diplomatic\s+meeting": "å¤–äº¤ä¼šè«‡",

	# ç´›äº‰ãƒ»è»äº‹
	r"missile\s+attack": "ãƒŸã‚µã‚¤ãƒ«æ”»æ’ƒ",
	r"air\s+strike": "ç©ºçˆ†",
	r"military\s+operation": "è»äº‹ä½œæˆ¦",
	r"ceasefire\s+deal": "åœæˆ¦åˆæ„",
	r"security\s+forces": "æ²»å®‰éƒ¨éšŠ",

	# çµŒæ¸ˆ
	r"stock\s+market": "æ ªå¼å¸‚å ´",
	r"economic\s+growth": "çµŒæ¸ˆæˆé•·",
	r"oil\s+prices": "åŸæ²¹ä¾¡æ ¼",
	r"interest\s+rates": "é‡‘åˆ©",

	# ç’°å¢ƒ
	r"climate\s+change": "æ°—å€™å¤‰å‹•",
	r"global\s+warming": "åœ°çƒæ¸©æš–åŒ–",
	r"renewable\s+energy": "å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼",

	# å¥åº·
	r"health\s+crisis": "å¥åº·å±æ©Ÿ",
	r"medical\s+breakthrough": "åŒ»å­¦çš„çªç ´",

	# ç½å®³
	r"natural\s+disaster": "è‡ªç„¶ç½å®³",
	r"emergency\s+response": "ç·Šæ€¥å¯¾å¿œ",

	# ãƒ‹ãƒ¥ãƒ¼ã‚¹è¡¨ç¾
	r"breaking\s+news": "é€Ÿå ±",
	r"latest\s+update": "æœ€æ–°æƒ…å ±",
	r"official\s+statement": "å…¬å¼ç™ºè¡¨"
}

# åœ°åŸŸãƒ»çµ„ç¹”å
REGIONS_ORGS = {
	"European Union": "EU", "United Nations": "å›½é€£", "NATO": "NATO",
	"Middle East": "ä¸­æ±", "Southeast Asia": "æ±å—ã‚¢ã‚¸ã‚¢",
	"Eastern Europe": "æ±æ¬§", "Western Europe": "è¥¿æ¬§"
}

# é‡è¦äººç‰©
KEY_FIGURES = {
	"Donald Trump": "ãƒˆãƒ©ãƒ³ãƒ—å¤§çµ±é ˜", "Joe Biden": "ãƒã‚¤ãƒ‡ãƒ³å‰å¤§çµ±é ˜",
	"Vladimir Putin": "ãƒ—ãƒ¼ãƒãƒ³å¤§çµ±é ˜", "Xi Jinping": "ç¿’è¿‘å¹³å›½å®¶ä¸»å¸­",
	"Volodymyr Zelensky": "ã‚¼ãƒ¬ãƒ³ã‚¹ã‚­ãƒ¼å¤§çµ±é ˜", "Benjamin Netanyahu": "ãƒã‚¿ãƒ‹ãƒ¤ãƒ•é¦–ç›¸"
}

# åŸºæœ¬å›½å
COUNTRIES = {
	"China": "ä¸­å›½", "Russia": "ãƒ­ã‚·ã‚¢", "Ukraine": "ã‚¦ã‚¯ãƒ©ã‚¤ãƒŠ", "Israel": "ã‚¤ã‚¹ãƒ©ã‚¨ãƒ«",
	"Iran": "ã‚¤ãƒ©ãƒ³", "Germany": "ãƒ‰ã‚¤ãƒ„", "France": "ãƒ•ãƒ©ãƒ³ã‚¹", "UK": "è‹±å›½",
	"USA": "ç±³å›½", "US": "ç±³å›½", "Japan": "æ—¥æœ¬", "South Korea": "éŸ“å›½",
	"North Korea": "åŒ—æœé®®", "India": "ã‚¤ãƒ³ãƒ‰", "Australia": "è±ªå·"
}

def symbolic_translate(title):
	"""è±¡å¾´çš„ç¿»è¨³å®Ÿè¡Œ"""
	translated = title

	# ãƒ‘ã‚¿ãƒ¼ãƒ³ç¿»è¨³
	for pattern, replacement in TRANSLATION_PATTERNS.items():
		translated = re.sub(pattern, replacement, translated, flags=re.IGNORECASE)

	# åœ°åŸŸãƒ»çµ„ç¹”ç¿»è¨³
	for eng, jp in REGIONS_ORGS.items():
		translated = re.sub(r'\b' + re.escape(eng) + r'\b', jp, translated, flags=re.IGNORECASE)

	# äººç‰©ç¿»è¨³
	for eng, jp in KEY_FIGURES.items():
		translated = re.sub(r'\b' + re.escape(eng) + r'\b', jp, translated, flags=re.IGNORECASE)

	# å›½åç¿»è¨³
	for eng, jp in COUNTRIES.items():
		translated = re.sub(r'\b' + re.escape(eng) + r'\b', jp, translated, flags=re.IGNORECASE)

	# å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿ä½µè¨˜
	if translated.lower() != title.lower():
		return f"{title} ({translated})"
	else:
		return title

# ======================================
# è¨˜äº‹åˆ†ææ©Ÿèƒ½
# ======================================

def analyze_article_tags(title, summary):
	"""è¨˜äº‹ã‚¿ã‚°åˆ†æ"""
	text = (title + " " + summary).lower()
	scores = {}

	for category, data in ARTICLE_CATEGORIES.items():
		score = sum(1 for keyword in data["keywords"] if keyword in text)
		if score > 0:
			scores[category] = score

	# ä¸Šä½3ã¤ã¾ã§ã®ã‚¿ã‚°
	sorted_tags = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]

	return [
		{
			"name": category,
			"icon": ARTICLE_CATEGORIES[category]["icon"]
		}
		for category, score in sorted_tags
	] if sorted_tags else [{"name": "ä¸€èˆ¬", "icon": "ğŸ“°"}]

# ======================================
# APIæ©Ÿèƒ½ï¼ˆæ”¹å–„ç‰ˆï¼‰
# ======================================

def get_api_quote():
	"""APIçµŒç”±ã§è‹±èªåè¨€å–å¾—ï¼ˆè¤‡æ•°APIå¯¾å¿œï¼‰"""
	for api_url in QUOTE_API_URLS:
		try:
			response = requests.get(api_url, timeout=10, verify=False)
			if response.status_code == 200:
				data = response.json()

				if api_url == "https://api.quotable.io/random":
					return {
						"quote": data.get("content", ""),
						"author": data.get("author", "Unknown"),
						"translation": ""
					}
				elif api_url == "https://zenquotes.io/api/random":
					if isinstance(data, list) and len(data) > 0:
						return {
							"quote": data[0].get("q", ""),
							"author": data[0].get("a", "Unknown"),
							"translation": ""
						}
				print(f"âœ… åè¨€APIæˆåŠŸ: {api_url}")
				break
		except Exception as e:
			print(f"âš ï¸  åè¨€APIå¤±æ•— ({api_url}): {str(e)}")
			continue

	# å…¨ã¦ã®APIãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
	fallback_quotes = [
		{"quote": "The only way to do great work is to love what you do.", "author": "Steve Jobs"},
		{"quote": "Innovation distinguishes between a leader and a follower.", "author": "Steve Jobs"},
		{"quote": "Stay hungry, stay foolish.", "author": "Steve Jobs"},
		{"quote": "The future belongs to those who believe in the beauty of their dreams.", "author": "Eleanor Roosevelt"},
		{"quote": "It is during our darkest moments that we must focus to see the light.", "author": "Aristotle"},
	]

	return random.choice(fallback_quotes)

def get_api_history():
	"""APIçµŒç”±ã§ä»Šæ—¥ã¯ä½•ã®æ—¥å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
	try:
		today = date.today()
		url = f"{HISTORY_API_URL}/{today.month}/{today.day}"
		response = requests.get(url, timeout=10, verify=False)

		if response.status_code == 200:
			data = response.json()
			events = data.get("data", {}).get("Events", [])

			if events:
				# æ­´å²çš„ã«é‡è¦ãã†ãªã‚¤ãƒ™ãƒ³ãƒˆã‚’é¸æŠï¼ˆå¤ã„å¹´ä»£ã‚’å„ªå…ˆï¼‰
				important_events = sorted(events, key=lambda x: int(x.get("year", "0")))
				selected_event = important_events[0] if important_events else events[0]

				year = selected_event.get("year", "")
				text = selected_event.get("text", "")

				return f"{year} - {text[:150]}{'...' if len(text) > 150 else ''}"

		print("âœ… æ­´å²APIæˆåŠŸ")

	except Exception as e:
		print(f"âš ï¸  æ­´å²APIå¤±æ•—: {str(e)}")

	# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
	today = date.today()
	fallback_events = [
		f"{today.month}æœˆ{today.day}æ—¥ - ä»Šæ—¥ã¨ã„ã†æ—¥ã¯äºŒåº¦ã¨æ¥ãªã„ç‰¹åˆ¥ãªæ—¥ã§ã™ã€‚æ–°ã—ã„ç™ºè¦‹ã¨å­¦ã³ã‚’å¤§åˆ‡ã«ã—ã¾ã—ã‚‡ã†ã€‚",
		f"{today.month}æœˆ{today.day}æ—¥ - æ­´å²ã¯æ¯æ—¥ä½œã‚‰ã‚Œã¦ã„ã¾ã™ã€‚ä»Šæ—¥ã‚‚æ–°ã—ã„ä¸€æ­©ã‚’è¸ã¿å‡ºã—ã¾ã—ã‚‡ã†ã€‚",
		f"{today.month}æœˆ{today.day}æ—¥ - éå»ã‹ã‚‰å­¦ã³ã€ç¾åœ¨ã‚’ç”Ÿãã€æœªæ¥ã«å¸Œæœ›ã‚’æŒã¡ã¾ã—ã‚‡ã†ã€‚"
	]

	return random.choice(fallback_events)

# ======================================
# ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰
# ======================================

# æ›´æ–°ã•ã‚ŒãŸãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹ï¼ˆå‹•ä½œç¢ºèªæ¸ˆã¿URLï¼‰
JAPANESE_NEWS_SOURCES = [
	("NHK ä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹", "https://www.nhk.or.jp/rss/news/cat0.xml", 15),
	("NHK ç¤¾ä¼š", "https://www.nhk.or.jp/rss/news/cat1.xml", 10),
	("NHK æ”¿æ²»", "https://www.nhk.or.jp/rss/news/cat4.xml", 10),
	("NHK çµŒæ¸ˆ", "https://www.nhk.or.jp/rss/news/cat5.xml", 10),
	("NHK å›½éš›", "https://www.nhk.or.jp/rss/news/cat6.xml", 10),
	("NHK ç§‘å­¦æ–‡åŒ–", "https://www.nhk.or.jp/rss/news/cat3.xml", 8),
	("Yahooä¸»è¦ãƒ‹ãƒ¥ãƒ¼ã‚¹", "https://news.yahoo.co.jp/rss/topics/top-picks.xml", 12),
	("Yahooå›½å†…", "https://news.yahoo.co.jp/rss/topics/domestic.xml", 10),
	("YahooçµŒæ¸ˆ", "https://news.yahoo.co.jp/rss/topics/business.xml", 8),
	("Yahooå›½éš›", "https://news.yahoo.co.jp/rss/topics/world.xml", 8),
	("æ™‚äº‹é€šä¿¡", "https://www.jiji.com/rss/ranking.rdf", 8),
	("æœæ—¥æ–°è", "https://www.asahi.com/rss/asahi/newsheadlines.rdf", 8)  # å…±åŒé€šä¿¡ä»£æ›¿
]

INTERNATIONAL_NEWS_SOURCES = [
	("BBC World", "http://feeds.bbci.co.uk/news/world/rss.xml", 8),
	("BBC UK", "http://feeds.bbci.co.uk/news/uk/rss.xml", 5),
	("The Guardian World", "https://www.theguardian.com/world/rss", 5),
	("ABC Australia", "https://www.abc.net.au/news/feed/45924/rss.xml", 4),
	("Deutsche Welle", "https://rss.dw.com/rdf/rss-en-all", 5),
	("France 24", "https://www.france24.com/en/rss", 4),
	("Al Jazeera", "https://www.aljazeera.com/xml/rss/all.xml", 6),
	("Sky News", "https://feeds.skynews.com/feeds/rss/world.xml", 4),
	("CNN International", "http://rss.cnn.com/rss/edition.rss", 5),
	("Euronews", "https://feeds.feedburner.com/euronews/en/news", 4)
]

EXCLUDE_KEYWORDS = [
	"å¥³æ€§è‡ªèº«", "å¥³æ€§ã‚»ãƒ–ãƒ³", "é€±åˆŠå¥³æ€§", "FLASH", "FRIDAY", "é€±åˆŠæ–‡æ˜¥", "é€±åˆŠæ–°æ½®",
	"æ—¥åˆŠã‚²ãƒ³ãƒ€ã‚¤", "æ±ã‚¹ãƒ", "ã‚µãƒ³ã‚¹ãƒ", "ãƒ‡ã‚¤ãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒ„", "å¤•åˆŠãƒ•ã‚¸", "æ—¥åˆŠã‚¹ãƒãƒ¼ãƒ„",
	"èŠ¸èƒ½", "ä¸å€«", "æµ®æ°—", "é›¢å©š", "ç‚ä¸Š", "æš´éœ²", "æ¿€æ€’", "è¡æ’ƒ",
	"ç·Šæ€¥äº‹æ…‹", "å¤§ç‚ä¸Š", "æ‰¹åˆ¤æ®ºåˆ°", "ç‰©è­°", "è©±é¡Œé¨’ç„¶", "è³›å¦ä¸¡è«–",
	"AV", "é¢¨ä¿—", "ãƒ‘ãƒãƒ³ã‚³", "ç«¶é¦¬", "å®ãã˜", "ã‚®ãƒ£ãƒ³ãƒ–ãƒ«", "è©æ¬º"
]

def fetch_rss_with_tags(source_name, url, max_items):
	"""RSSãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ç‰ˆï¼‰"""
	if not LIBS_AVAILABLE:
		return []

	try:
		print(f"ğŸ“¡ {source_name} ã‹ã‚‰å–å¾—ä¸­...")

		# User-Agentã‚’è¨­å®šã—ã¦ãƒ–ãƒ­ãƒƒã‚¯å›é¿
		headers = {
			'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
		}

		# HTTPSã®å ´åˆã¯verify=Falseã‚’è¿½åŠ 
		response = requests.get(url, headers=headers, timeout=15, verify=False)
		response.raise_for_status()

		# feedparserã«æ¸¡ã™ãŸã‚ã«BytesIOã‚’ä½¿ç”¨
		from io import BytesIO
		feed = feedparser.parse(BytesIO(response.content))

		if not feed.entries:
			print(f"âš ï¸  {source_name}: RSSã‚¨ãƒ³ãƒˆãƒªãŒç©º")
			return []

		articles = []

		for entry in feed.entries[:max_items * 3]:
			try:
				title = entry.title.strip() if hasattr(entry, 'title') else "ã‚¿ã‚¤ãƒˆãƒ«ãªã—"

				if any(keyword in title for keyword in EXCLUDE_KEYWORDS):
					continue

				summary = ""
				if hasattr(entry, 'summary'):
					summary = entry.summary
				elif hasattr(entry, 'description'):
					summary = entry.description

				if summary:
					summary = re.sub(r'<[^>]+>', '', summary)
					summary = summary.strip()
					if len(summary) > 120:
						summary = summary[:120] + "..."

				# ãƒªãƒ³ã‚¯URLå–å¾—
				link = entry.link if hasattr(entry, 'link') else ""

				# ã‚¿ã‚°åˆ†æ
				tags = analyze_article_tags(title, summary)

				# å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®å ´åˆã¯ç¿»è¨³
				if source_name not in [src[0] for src in JAPANESE_NEWS_SOURCES]:
					translated_title = symbolic_translate(title)
				else:
					translated_title = title

				articles.append({
					'title': translated_title,
					'summary': summary,
					'url': link,
					'source': source_name,
					'tags': tags[:2]  # æœ€å¤§2ã‚¿ã‚°
				})

				if len(articles) >= max_items:
					break

			except Exception as e:
				print(f"âš ï¸  {source_name} ã‚¨ãƒ³ãƒˆãƒªå‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
				continue

		print(f"âœ… {source_name}: {len(articles)}ä»¶å–å¾—")
		return articles

	except requests.exceptions.RequestException as e:
		print(f"âŒ {source_name} HTTPå–å¾—å¤±æ•—: {str(e)}")
		return []
	except Exception as e:
		print(f"âŒ {source_name} å–å¾—å¤±æ•—: {str(e)}")
		return []

def get_all_news():
	"""å…¨ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
	all_news = {'japanese': [], 'international': []}

	if not LIBS_AVAILABLE:
		return all_news

	print("ğŸ“° æ—¥æœ¬èªãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—é–‹å§‹...")
	for source_name, url, max_items in JAPANESE_NEWS_SOURCES:
		articles = fetch_rss_with_tags(source_name, url, max_items)
		all_news['japanese'].extend(articles)
		time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ

	print("ğŸŒ å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—é–‹å§‹...")
	for source_name, url, max_items in INTERNATIONAL_NEWS_SOURCES:
		articles = fetch_rss_with_tags(source_name, url, max_items)
		all_news['international'].extend(articles)
		time.sleep(1)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ

	# é‡è¤‡é™¤å»
	all_news['japanese'] = remove_duplicates(all_news['japanese'])
	all_news['international'] = remove_duplicates(all_news['international'])

	print(f"ğŸ“Š ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—å®Œäº†: å›½å†…{len(all_news['japanese'])}ä»¶ã€å›½éš›{len(all_news['international'])}ä»¶")

	return all_news

def remove_duplicates(articles):
	"""è¨˜äº‹é‡è¤‡é™¤å»"""
	seen_titles = set()
	unique_articles = []

	for article in articles:
		title_words = set(article['title'].lower().split())
		is_duplicate = False

		for seen_title in seen_titles:
			seen_words = set(seen_title.lower().split())
			if len(title_words & seen_words) / len(title_words | seen_words) > 0.7:
				is_duplicate = True
				break

		if not is_duplicate:
			seen_titles.add(article['title'])
			unique_articles.append(article)

	return unique_articles

# ======================================
# å¤©æ°—å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰
# ======================================

def get_weather_data():
	"""å¤©æ°—ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
	if not LIBS_AVAILABLE:
		return get_fallback_weather()

	try:
		url = "https://api.open-meteo.com/v1/forecast"
		params = {
			'latitude': LATITUDE,
			'longitude': LONGITUDE,
			'hourly': 'temperature_2m,weather_code',
			'daily': 'temperature_2m_max,temperature_2m_min,weather_code',
			'timezone': 'Asia/Tokyo',
			'forecast_days': 3
		}

		response = requests.get(url, params=params, timeout=15, verify=False)
		response.raise_for_status()
		data = response.json()

		weather_codes = {
			0: "å¿«æ™´", 1: "æ™´ã‚Œ", 2: "éƒ¨åˆ†çš„ã«æ›‡ã‚Š", 3: "æ›‡ã‚Š",
			45: "éœ§", 48: "éœ§æ°·", 51: "å°é›¨", 53: "é›¨", 55: "å¼·é›¨",
			61: "é›¨", 63: "é›¨", 65: "å¼·é›¨", 71: "é›ª", 73: "é›ª", 75: "å¤§é›ª",
			77: "ã¿ãã‚Œ", 80: "ã«ã‚ã‹é›¨", 81: "ã«ã‚ã‹é›¨", 82: "å¼·ã„ã«ã‚ã‹é›¨",
			85: "é›ª", 86: "å¤§é›ª", 95: "é›·é›¨", 96: "é›·é›¨", 99: "é›·é›¨"
		}

		now_hour = min(datetime.now().hour, len(data['hourly']['temperature_2m']) - 1)
		current_temp = round(data['hourly']['temperature_2m'][now_hour])
		current_code = data['hourly']['weather_code'][now_hour]
		current_weather = weather_codes.get(current_code, "ä¸æ˜")

		weekly_forecast = []
		days = ["ä»Šæ—¥", "æ˜æ—¥", "æ˜å¾Œæ—¥"]
		for i in range(3):
			max_temp = round(data['daily']['temperature_2m_max'][i])
			min_temp = round(data['daily']['temperature_2m_min'][i])
			code = data['daily']['weather_code'][i]
			weather_desc = weather_codes.get(code, "ä¸æ˜")
			weekly_forecast.append({
				'date': days[i],
				'high': f"{max_temp}Â°C",
				'low': f"{min_temp}Â°C",
				'weather': weather_desc
			})

		print(f"âœ… {LOCATION_NAME}ã®å¤©æ°—å–å¾—: {current_temp}Â°C - {current_weather}")

		return {
			'current_temp': f"{current_temp}Â°C",
			'current_weather': current_weather,
			'weekly': weekly_forecast
		}

	except Exception as e:
		print(f"âš ï¸  å¤©æ°—APIå¤±æ•—: {str(e)}")
		return get_fallback_weather()

def get_fallback_weather():
	"""ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¤©æ°—"""
	return {
		'current_temp': "15Â°C",
		'current_weather': "æ™´ã‚Œ",
		'weekly': [
			{'date': 'ä»Šæ—¥', 'high': '20Â°C', 'low': '8Â°C', 'weather': 'æ™´ã‚Œ'},
			{'date': 'æ˜æ—¥', 'high': '22Â°C', 'low': '10Â°C', 'weather': 'æ›‡ã‚Š'},
			{'date': 'æ˜å¾Œæ—¥', 'high': '19Â°C', 'low': '9Â°C', 'weather': 'é›¨'}
		]
	}

# ======================================
# HTMLç”Ÿæˆï¼ˆæ”¹å–„ç‰ˆï¼‰
# ======================================

def generate_nhk_style_newspaper():
	"""NHKã‚¹ã‚¿ã‚¤ãƒ«æ–°èHTMLç”Ÿæˆ"""
	today = date.today()
	now = datetime.now()

	print("ğŸ“° NHKã‚¹ã‚¿ã‚¤ãƒ«æ–°èç”Ÿæˆä¸­...")

	quote = get_api_quote()
	history = get_api_history()
	weather = get_weather_data()
	news = get_all_news()

	weekdays = ["æœˆæ›œæ—¥", "ç«æ›œæ—¥", "æ°´æ›œæ—¥", "æœ¨æ›œæ—¥", "é‡‘æ›œæ—¥", "åœŸæ›œæ—¥", "æ—¥æ›œæ—¥"]
	weekday_jp = weekdays[today.weekday()]

	html = f"""<!DOCTYPE html>
<html lang="ja">
<head>
	<meta charset="UTF-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è - {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}</title>
	<style>
		body {{
			font-family: 'Hiragino Sans', 'Yu Gothic', 'Meiryo', sans-serif;
			font-size: 16px;
			line-height: 1.7;
			max-width: 1000px;
			margin: 0 auto;
			padding: 15px;
			background-color: #fff;
			color: #333;
		}}
		.header {{
			background: #003f7f;
			color: white;
			padding: 20px;
			margin-bottom: 20px;
			border-radius: 5px;
		}}
		.header h1 {{
			margin: 0;
			font-size: 28px;
			font-weight: bold;
		}}
		.header .date {{
			margin: 8px 0 0 0;
			font-size: 18px;
		}}
		.info-bar {{
			display: grid;
			grid-template-columns: 1fr 1fr 1fr;
			gap: 15px;
			margin-bottom: 25px;
		}}
		.info-box {{
			background: #f5f5f5;
			padding: 15px;
			border-radius: 5px;
			border-left: 4px solid #003f7f;
		}}
		.info-box h3 {{
			margin: 0 0 10px 0;
			font-size: 16px;
			color: #003f7f;
			font-weight: bold;
		}}
		.weather-mini {{
			display: flex;
			justify-content: space-between;
			font-size: 14px;
		}}
		.weather-day {{
			text-align: center;
		}}
		.quote-text {{
			font-size: 14px;
			font-style: italic;
			color: #555;
		}}
		.main-content {{
			display: grid;
			grid-template-columns: 2fr 1fr;
			gap: 25px;
		}}
		.news-section {{
			background: white;
		}}
		.news-title {{
			font-size: 22px;
			font-weight: bold;
			color: #003f7f;
			margin: 0 0 15px 0;
			padding-bottom: 8px;
			border-bottom: 3px solid #003f7f;
		}}
		.news-item {{
			margin-bottom: 20px;
			padding: 15px;
			border: 1px solid #ddd;
			border-radius: 5px;
			background: #fafafa;
		}}
		.news-tags {{
			margin-bottom: 8px;
		}}
		.tag {{
			display: inline-block;
			background: #e1f5fe;
			color: #0277bd;
			padding: 2px 8px;
			border-radius: 10px;
			font-size: 12px;
			margin-right: 5px;
		}}
		.news-headline {{
			font-size: 16px;
			font-weight: bold;
			margin: 8px 0;
			line-height: 1.4;
		}}
		.news-headline a {{
			color: #333;
			text-decoration: none;
		}}
		.news-headline a:hover {{
			color: #003f7f;
			text-decoration: underline;
		}}
		.news-summary {{
			font-size: 14px;
			color: #666;
			margin: 8px 0;
		}}
		.news-source {{
			font-size: 12px;
			color: #888;
		}}
		.sidebar {{
			background: #f8f9fa;
			padding: 15px;
			border-radius: 5px;
		}}
		.sidebar h3 {{
			color: #003f7f;
			font-size: 16px;
			margin: 0 0 10px 0;
			border-bottom: 2px solid #003f7f;
			padding-bottom: 5px;
		}}
		.sidebar-content {{
			font-size: 14px;
			line-height: 1.6;
		}}
		.stats-item {{
			display: flex;
			justify-content: space-between;
			margin: 5px 0;
			padding: 5px 0;
			border-bottom: 1px dotted #ccc;
		}}
		.footer {{
			background: #003f7f;
			color: white;
			text-align: center;
			padding: 15px;
			margin-top: 30px;
			border-radius: 5px;
		}}
		.note {{
			background: #fff3cd;
			border: 1px solid #ffeaa7;
			padding: 10px;
			margin: 15px 0;
			border-radius: 5px;
			font-size: 14px;
			color: #856404;
		}}
		.success {{
			background: #d4edda;
			border: 1px solid #c3e6cb;
			color: #155724;
		}}
		@media (max-width: 768px) {{
			.main-content {{
				grid-template-columns: 1fr;
			}}
			.info-bar {{
				grid-template-columns: 1fr;
			}}
		}}
	</style>
</head>
<body>
	<div class="header">
		<h1>ğŸ“° ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è</h1>
		<div class="date">{today.strftime('%Yå¹´%mæœˆ%dæ—¥')} ({weekday_jp})</div>
	</div>

	<div class="info-bar">
		<div class="info-box">
			<h3>ğŸŒ¤ï¸ {LOCATION_NAME}ã®å¤©æ°—</h3>
			<div style="text-align: center; margin-bottom: 10px;">
				<strong>{weather['current_temp']} {weather['current_weather']}</strong>
			</div>
			<div class="weather-mini">"""

	for item in weather['weekly']:
		html += f"""
				<div class="weather-day">
					<div style="font-weight: bold;">{item['date']}</div>
					<div>{item['high']}/{item['low']}</div>
					<div style="font-size: 12px;">{item['weather']}</div>
				</div>"""

	html += f"""
			</div>
		</div>

		<div class="info-box">
			<h3>ğŸ“š ä»Šæ—¥ã¯ä½•ã®æ—¥</h3>
			<div style="font-size: 14px; line-height: 1.5;">
				{history[:120]}{'...' if len(history) > 120 else ''}
			</div>
		</div>

		<div class="info-box">
			<h3>ğŸ’­ ä»Šæ—¥ã®è¨€è‘‰</h3>
			<div class="quote-text">
				"{quote['quote'][:70]}{'...' if len(quote['quote']) > 70 else ''}"
				<div style="text-align: right; margin-top: 5px; font-weight: bold;">
					â€” {quote['author']}
				</div>
			</div>
		</div>
	</div>

	<div class="main-content">
		<div class="news-section">
			<h2 class="news-title">ğŸ‡¯ğŸ‡µ å›½å†…ãƒ‹ãƒ¥ãƒ¼ã‚¹</h2>
			<div class="note success">
				âœ… NHKãƒ»Yahooãƒ»æ™‚äº‹é€šä¿¡ãªã©ä¿¡é ¼ã§ãã‚‹å ±é“æ©Ÿé–¢ã‹ã‚‰{len(news['japanese'])}ä»¶ã‚’è‡ªå‹•å–å¾—
			</div>"""

	# æ—¥æœ¬ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆåˆ¶é™ãªã—ã§å…¨ä»¶è¡¨ç¤ºï¼‰
	for article in news['japanese']:
		tags_html = ''.join([f'<span class="tag">{tag["icon"]} {tag["name"]}</span>' for tag in article["tags"]])
		html += f"""
			<div class="news-item">
				<div class="news-tags">
					{tags_html}
				</div>
				<div class="news-headline">
					<a href="{article['url']}" target="_blank">{article['title']}</a>
				</div>
				<div class="news-summary">{article['summary']}</div>
				<div class="news-source">å‡ºå…¸: {article['source']}</div>
			</div>"""

	html += f"""
			<h2 class="news-title">ğŸŒ å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹</h2>
			<div class="note success">
				âœ… BBCãƒ»Guardianãƒ»Deutsche Welleãƒ»åœ°åŸŸãƒ¡ãƒ‡ã‚£ã‚¢ã‹ã‚‰{len(news['international'])}ä»¶ã‚’è‡ªå‹•å–å¾—ãƒ»ç¿»è¨³
			</div>"""

	# å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆåˆ¶é™ãªã—ã§å…¨ä»¶è¡¨ç¤ºï¼‰
	for article in news['international']:
		tags_html = ''.join([f'<span class="tag">{tag["icon"]} {tag["name"]}</span>' for tag in article["tags"]])
		html += f"""
			<div class="news-item">
				<div class="news-tags">
					{tags_html}
				</div>
				<div class="news-headline">
					<a href="{article['url']}" target="_blank">{article['title']}</a>
				</div>
				<div class="news-summary">{article['summary']}</div>
				<div class="news-source">å‡ºå…¸: {article['source']}</div>
			</div>"""

	# ã‚¿ã‚°çµ±è¨ˆã‚’ç”Ÿæˆ
	all_tags = {}
	for article in news['japanese'] + news['international']:
		for tag in article['tags']:
			tag_name = tag['name']
			if tag_name in all_tags:
				all_tags[tag_name] += 1
			else:
				all_tags[tag_name] = 1

	sorted_tags = sorted(all_tags.items(), key=lambda x: x[1], reverse=True)[:5]

	html += f"""
		</div>

		<div class="sidebar">
			<h3>ğŸ“Š ä»Šæ—¥ã®è¨˜äº‹åˆ†æ</h3>
			<div class="sidebar-content">
				<div class="stats-item">
					<span><strong>ç·è¨˜äº‹æ•°</strong></span>
					<span><strong>{len(news['japanese']) + len(news['international'])}ä»¶</strong></span>
				</div>
				<div class="stats-item">
					<span>å›½å†…ãƒ‹ãƒ¥ãƒ¼ã‚¹</span>
					<span>{len(news['japanese'])}ä»¶</span>
				</div>
				<div class="stats-item">
					<span>å›½éš›ãƒ‹ãƒ¥ãƒ¼ã‚¹</span>
					<span>{len(news['international'])}ä»¶</span>
				</div>
				<hr style="margin: 15px 0;">
				<h4 style="margin: 10px 0; color: #003f7f;">ä¸»è¦ã‚«ãƒ†ã‚´ãƒª</h4>"""

	for tag_name, count in sorted_tags:
		html += f"""
				<div class="stats-item">
					<span>{tag_name}</span>
					<span>{count}ä»¶</span>
				</div>"""

	html += f"""
				<hr style="margin: 15px 0;">
				<p style="font-size: 13px; color: #666;">
					è¨˜äº‹ã¯å†…å®¹ã«åŸºã¥ã„ã¦è‡ªå‹•åˆ†é¡ã•ã‚Œã¾ã™ã€‚
					AIã«ã‚ˆã‚‹ã‚¿ã‚°ä»˜ã‘ã§åŠ¹ç‡çš„ãªæƒ…å ±åé›†ãŒå¯èƒ½ã§ã™ã€‚
				</p>
			</div>
		</div>
	</div>

	<div class="footer">
		<p><strong>ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è</strong></p>
		<p>ç™ºè¡Œ: {SENDER_NAME} | ç™ºè¡Œæ—¥æ™‚: {now.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}</p>
		<p>ğŸ“¡ è‡ªå‹•å–å¾—ãƒ»ğŸ” AIåˆ†æãƒ»ğŸ“§ è‡ªå‹•é…ä¿¡</p>
	</div>
</body>
</html>"""

	return html

# ======================================
# ãƒ¡ãƒ¼ãƒ«é€ä¿¡
# ======================================

def send_email(html_content):
	"""ãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
	today = date.today()
	subject = f"ğŸ“° ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°è - {today.strftime('%Yå¹´%mæœˆ%dæ—¥')}"

	try:
		msg = MIMEMultipart('alternative')
		msg['Subject'] = subject
		msg['From'] = SENDER_EMAIL
		msg['To'] = ", ".join(RECIPIENTS)

		html_part = MIMEText(html_content, 'html', 'utf-8')
		msg.attach(html_part)

		server = smtplib.SMTP('smtp.gmail.com', 587)
		server.starttls()
		server.login(SENDER_EMAIL, SENDER_PASSWORD)

		for recipient in RECIPIENTS:
			server.send_message(msg, to_addrs=[recipient])
			print(f"âœ… ãƒ¡ãƒ¼ãƒ«é€ä¿¡å®Œäº†: {recipient}")

		server.quit()
		return True

	except Exception as e:
		print(f"âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)}")
		return False

def main():
	"""ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
	print("ğŸ“° ã»ã¼æ—¥åˆŠãƒˆãƒ©ã‚¬ãƒ©æ–°èç”Ÿæˆé–‹å§‹")
	print(f"ğŸ“… ç™ºè¡Œæ—¥: {date.today().strftime('%Yå¹´%mæœˆ%dæ—¥')}")

	if not LIBS_AVAILABLE:
		print("âŒ pip install feedparser requests ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
		return

	# HTMLç”Ÿæˆ
	html_content = generate_nhk_style_newspaper()

	# ãƒ¡ãƒ¼ãƒ«é€ä¿¡
	print("\nğŸ“§ æ–°èé…ä¿¡ä¸­...")
	success = send_email(html_content)

	if success:
		print("ğŸ‰ æ–°èé…ä¿¡å®Œäº†ï¼")
	else:
		print("âŒ ãƒ¡ãƒ¼ãƒ«é€ä¿¡å¤±æ•—")
		print("ğŸ’¡ Gmailè¨­å®šç¢ºèª:")
		print("   1. 2æ®µéšèªè¨¼ã‚’æœ‰åŠ¹åŒ–")
		print("   2. ã‚¢ãƒ—ãƒªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ç”Ÿæˆ")
		print("   3. SENDER_PASSWORDã«16æ–‡å­—ã®ã‚¢ãƒ—ãƒªãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’è¨­å®š")

	print(f"\nğŸ“Š æ”¹å–„å†…å®¹:")
	print(f"âœ… SSLè¨¼æ˜æ›¸ã‚¨ãƒ©ãƒ¼å¯¾å¿œï¼ˆverify=Falseï¼‰")
	print(f"âœ… RSSãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—ã®æ”¹å–„ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãƒ»ãƒ˜ãƒƒãƒ€ãƒ¼è¨­å®šï¼‰")
	print(f"âœ… è¤‡æ•°APIå¯¾å¿œï¼ˆåè¨€ãƒ»æ­´å²ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰")
	print(f"âœ… è¨˜äº‹é‡è¤‡é™¤å»æ©Ÿèƒ½è¿½åŠ ")
	print(f"âœ… ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–")
	print(f"âœ… å…¨è¨˜äº‹ã‚’æ–°èã«åæ˜ ï¼ˆä»¶æ•°åˆ¶é™æ’¤å»ƒï¼‰")
	print(f"âœ… å‹•ä½œä¸å®‰å®šã‚½ãƒ¼ã‚¹é™¤å¤–ï¼ˆReutersãƒ»AP Newså‰Šé™¤ï¼‰")
	print(f"âœ… ãƒ­ãƒ¼ã‚«ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å‰Šé™¤ï¼ˆãƒ¡ãƒ¼ãƒ«é…ä¿¡ã®ã¿ï¼‰")

if __name__ == "__main__":
	main()
